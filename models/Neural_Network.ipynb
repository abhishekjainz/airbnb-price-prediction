{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsrCg9bGBlid",
        "outputId": "6fe96d45-9f9b-45af-e852-f6c8dc6d7f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('/content/drive/My Drive/BT4222 Data Mining/Code & Data/cleaned_data.csv', na_filter=False)\n",
        "data.drop(['Unnamed: 0', 'property_type'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "2YkCBFdMByie",
        "outputId": "40659fa0-36ba-432c-bbe9-4a0331b3d503"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  host_response_time    host_response_rate host_acceptance_rate  \\\n",
              "0     within an hour  extremely responsive                  low   \n",
              "1     within an hour  extremely responsive              average   \n",
              "2     within an hour  extremely responsive       extremely high   \n",
              "3     within an hour  extremely responsive       extremely high   \n",
              "4     within an hour  extremely responsive                 high   \n",
              "\n",
              "   host_is_superhost  host_identity_verified  latitude  longitude  \\\n",
              "0                0.0                     1.0  32.80751 -117.25760   \n",
              "1                0.0                     1.0  32.74217 -117.21931   \n",
              "2                1.0                     1.0  32.79783 -117.25416   \n",
              "3                1.0                     1.0  32.80751 -117.25728   \n",
              "4                1.0                     1.0  32.81301 -117.26856   \n",
              "\n",
              "         room_type  accommodates  bedrooms  beds  price  minimum_nights  \\\n",
              "0  Entire home/apt             8       2.0   3.0  225.0               4   \n",
              "1     Private room             1       1.0   1.0  113.0               1   \n",
              "2  Entire home/apt             7       1.0   5.0  258.0               6   \n",
              "3  Entire home/apt             8       1.0   6.0  336.0               6   \n",
              "4  Entire home/apt             3       2.0   3.0  333.0               5   \n",
              "\n",
              "   maximum_nights  availability_30  number_of_reviews review_scores_rating  \\\n",
              "0             365                0                 88           4.7 to 4.8   \n",
              "1              21               20                149           4.3 to 4.4   \n",
              "2             365                0                162           4.7 to 4.8   \n",
              "3              90               16                183           4.7 to 4.8   \n",
              "4             120                6                296           4.9 to 5.0   \n",
              "\n",
              "   instant_bookable  reviews_per_month      state  has_license  bathrooms  \\\n",
              "0                 0               0.59  San Diego            0        2.0   \n",
              "1                 0               1.02  San Diego            0        1.0   \n",
              "2                 1               1.20  San Diego            0        2.5   \n",
              "3                 1               1.38  San Diego            0        2.0   \n",
              "4                 0               2.08  San Diego            0        1.0   \n",
              "\n",
              "  bathroom_type  num_of_amenities  essentials  luxury  appliances  comfort  \\\n",
              "0         baths                21           2       2           3        1   \n",
              "1        shared                29           4       3           2        2   \n",
              "2         baths                41           2       4           8        1   \n",
              "3         baths                52           4       5           8        1   \n",
              "4          bath                59           6       3           7        1   \n",
              "\n",
              "   entertainment  security  furniture  miscellaneous description_sentiment  \\\n",
              "0              2         2          0              9     Slightly Positive   \n",
              "1              2         2          1             13     Slightly Positive   \n",
              "2              1         3          1             21               Neutral   \n",
              "3              2         3          3             26     Slightly Positive   \n",
              "4              2         2          2             36               Neutral   \n",
              "\n",
              "  neighborhood_overview_sentiment host_gender  sentiment_mean_score  \n",
              "0                              NA        male              0.879871  \n",
              "1               Slightly Positive      female              0.797530  \n",
              "2               Slightly Positive      female              0.843751  \n",
              "3                         Neutral      female              0.860047  \n",
              "4               Slightly Positive      female              0.903197  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3aba5c09-6f75-4021-94fd-63fe2a7e2911\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>host_response_time</th>\n",
              "      <th>host_response_rate</th>\n",
              "      <th>host_acceptance_rate</th>\n",
              "      <th>host_is_superhost</th>\n",
              "      <th>host_identity_verified</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>room_type</th>\n",
              "      <th>accommodates</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>beds</th>\n",
              "      <th>price</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>maximum_nights</th>\n",
              "      <th>availability_30</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>review_scores_rating</th>\n",
              "      <th>instant_bookable</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>state</th>\n",
              "      <th>has_license</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bathroom_type</th>\n",
              "      <th>num_of_amenities</th>\n",
              "      <th>essentials</th>\n",
              "      <th>luxury</th>\n",
              "      <th>appliances</th>\n",
              "      <th>comfort</th>\n",
              "      <th>entertainment</th>\n",
              "      <th>security</th>\n",
              "      <th>furniture</th>\n",
              "      <th>miscellaneous</th>\n",
              "      <th>description_sentiment</th>\n",
              "      <th>neighborhood_overview_sentiment</th>\n",
              "      <th>host_gender</th>\n",
              "      <th>sentiment_mean_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>within an hour</td>\n",
              "      <td>extremely responsive</td>\n",
              "      <td>low</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>32.80751</td>\n",
              "      <td>-117.25760</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>4</td>\n",
              "      <td>365</td>\n",
              "      <td>0</td>\n",
              "      <td>88</td>\n",
              "      <td>4.7 to 4.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.59</td>\n",
              "      <td>San Diego</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>baths</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>Slightly Positive</td>\n",
              "      <td>NA</td>\n",
              "      <td>male</td>\n",
              "      <td>0.879871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>within an hour</td>\n",
              "      <td>extremely responsive</td>\n",
              "      <td>average</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>32.74217</td>\n",
              "      <td>-117.21931</td>\n",
              "      <td>Private room</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>20</td>\n",
              "      <td>149</td>\n",
              "      <td>4.3 to 4.4</td>\n",
              "      <td>0</td>\n",
              "      <td>1.02</td>\n",
              "      <td>San Diego</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>shared</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>Slightly Positive</td>\n",
              "      <td>Slightly Positive</td>\n",
              "      <td>female</td>\n",
              "      <td>0.797530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>within an hour</td>\n",
              "      <td>extremely responsive</td>\n",
              "      <td>extremely high</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>32.79783</td>\n",
              "      <td>-117.25416</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>258.0</td>\n",
              "      <td>6</td>\n",
              "      <td>365</td>\n",
              "      <td>0</td>\n",
              "      <td>162</td>\n",
              "      <td>4.7 to 4.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1.20</td>\n",
              "      <td>San Diego</td>\n",
              "      <td>0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>baths</td>\n",
              "      <td>41</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Slightly Positive</td>\n",
              "      <td>female</td>\n",
              "      <td>0.843751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>within an hour</td>\n",
              "      <td>extremely responsive</td>\n",
              "      <td>extremely high</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>32.80751</td>\n",
              "      <td>-117.25728</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>336.0</td>\n",
              "      <td>6</td>\n",
              "      <td>90</td>\n",
              "      <td>16</td>\n",
              "      <td>183</td>\n",
              "      <td>4.7 to 4.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1.38</td>\n",
              "      <td>San Diego</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>baths</td>\n",
              "      <td>52</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>26</td>\n",
              "      <td>Slightly Positive</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>female</td>\n",
              "      <td>0.860047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>within an hour</td>\n",
              "      <td>extremely responsive</td>\n",
              "      <td>high</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>32.81301</td>\n",
              "      <td>-117.26856</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>5</td>\n",
              "      <td>120</td>\n",
              "      <td>6</td>\n",
              "      <td>296</td>\n",
              "      <td>4.9 to 5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.08</td>\n",
              "      <td>San Diego</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>bath</td>\n",
              "      <td>59</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>36</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Slightly Positive</td>\n",
              "      <td>female</td>\n",
              "      <td>0.903197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3aba5c09-6f75-4021-94fd-63fe2a7e2911')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3aba5c09-6f75-4021-94fd-63fe2a7e2911 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3aba5c09-6f75-4021-94fd-63fe2a7e2911');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax80-IEMB0MG",
        "outputId": "e237f412-a3ef-4945-8dc2-96f0f29b2959"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "host_response_time                  object\n",
              "host_response_rate                  object\n",
              "host_acceptance_rate                object\n",
              "host_is_superhost                  float64\n",
              "host_identity_verified             float64\n",
              "latitude                           float64\n",
              "longitude                          float64\n",
              "room_type                           object\n",
              "accommodates                         int64\n",
              "bedrooms                           float64\n",
              "beds                               float64\n",
              "price                              float64\n",
              "minimum_nights                       int64\n",
              "maximum_nights                       int64\n",
              "availability_30                      int64\n",
              "number_of_reviews                    int64\n",
              "review_scores_rating                object\n",
              "instant_bookable                     int64\n",
              "reviews_per_month                  float64\n",
              "state                               object\n",
              "has_license                          int64\n",
              "bathrooms                          float64\n",
              "bathroom_type                       object\n",
              "num_of_amenities                     int64\n",
              "essentials                           int64\n",
              "luxury                               int64\n",
              "appliances                           int64\n",
              "comfort                              int64\n",
              "entertainment                        int64\n",
              "security                             int64\n",
              "furniture                            int64\n",
              "miscellaneous                        int64\n",
              "description_sentiment               object\n",
              "neighborhood_overview_sentiment     object\n",
              "host_gender                         object\n",
              "sentiment_mean_score               float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = []\n",
        "categorical_columns = []\n",
        "boolean_columns = ['host_is_superhost', 'host_identity_verified', 'has_license', 'instant_bookable']\n",
        "ordered_columns = ['host_response_time', 'host_response_rate', 'host_acceptance_rate', 'review_scores_rating', 'description_sentiment', 'neighborhood_overview_sentiment']\n",
        "\n",
        "column_types = data.dtypes\n",
        "for i in range(len(column_types)):\n",
        "  if column_types[i] == 'object' and column_types.index[i] not in ordered_columns:\n",
        "    categorical_columns.append(column_types.index[i])\n",
        "  elif column_types.index[i] not in boolean_columns and column_types[i] != 'object':\n",
        "    numeric_columns.append(column_types.index[i])\n",
        "\n",
        "print(numeric_columns)\n",
        "print(categorical_columns)\n",
        "print(boolean_columns)\n",
        "print(ordered_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACYkGMB1xJqz",
        "outputId": "18b5c029-38d5-42e7-caff-70c0ab9b2eaa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['latitude', 'longitude', 'accommodates', 'bedrooms', 'beds', 'price', 'minimum_nights', 'maximum_nights', 'availability_30', 'number_of_reviews', 'reviews_per_month', 'bathrooms', 'num_of_amenities', 'essentials', 'luxury', 'appliances', 'comfort', 'entertainment', 'security', 'furniture', 'miscellaneous', 'sentiment_mean_score']\n",
            "['room_type', 'state', 'bathroom_type', 'host_gender']\n",
            "['host_is_superhost', 'host_identity_verified', 'has_license', 'instant_bookable']\n",
            "['host_response_time', 'host_response_rate', 'host_acceptance_rate', 'review_scores_rating', 'description_sentiment', 'neighborhood_overview_sentiment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[data.select_dtypes('object').columns].nunique().reset_index(name='cardinality')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "2se2rSlPEqZ5",
        "outputId": "5825e4fa-bcea-4107-9a38-bc1354b839ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             index  cardinality\n",
              "0               host_response_time            5\n",
              "1               host_response_rate            7\n",
              "2             host_acceptance_rate            7\n",
              "3                        room_type            4\n",
              "4             review_scores_rating           34\n",
              "5                            state            8\n",
              "6                    bathroom_type            6\n",
              "7            description_sentiment            8\n",
              "8  neighborhood_overview_sentiment            8\n",
              "9                      host_gender            3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-715c7634-8e59-4ad9-87fa-530d28c76e39\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>cardinality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>host_response_time</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>host_response_rate</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>host_acceptance_rate</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>room_type</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>review_scores_rating</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>state</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bathroom_type</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>description_sentiment</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>neighborhood_overview_sentiment</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>host_gender</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-715c7634-8e59-4ad9-87fa-530d28c76e39')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-715c7634-8e59-4ad9-87fa-530d28c76e39 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-715c7634-8e59-4ad9-87fa-530d28c76e39');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, other = train_test_split(data, train_size=0.7)\n",
        "val, test = train_test_split(other, test_size=0.5)\n",
        "train.reset_index(inplace=True)\n",
        "val.reset_index(inplace=True)\n",
        "test.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "V6kABZahBuhr"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.drop(['price'], axis=1)\n",
        "y_train = train['price']\n",
        "\n",
        "X_val = val.drop(['price'], axis=1)\n",
        "y_val = val['price']\n",
        "\n",
        "X_test = test.drop(['price'], axis=1)\n",
        "y_test = test['price']"
      ],
      "metadata": {
        "id": "8jcip_Iubcye"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using One-Hot Encoding"
      ],
      "metadata": {
        "id": "s3e1LTV9Y4WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
        "\n",
        "enc_X_train = pd.DataFrame()\n",
        "enc_X_val = pd.DataFrame()\n",
        "enc_X_test = pd.DataFrame()\n",
        "\n",
        "for column in X_train.columns:\n",
        "  if column in categorical_columns:\n",
        "    enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc_col_train = enc.fit_transform(X_train[[column]])\n",
        "    feature_names = enc.get_feature_names_out()\n",
        "    enc_X_train[feature_names] = pd.DataFrame.sparse.from_spmatrix(enc_col_train, columns=feature_names)\n",
        "\n",
        "    enc_col_val = enc.transform(X_val[[column]])\n",
        "    enc_X_val[feature_names] = pd.DataFrame.sparse.from_spmatrix(enc_col_val, columns=feature_names)\n",
        "\n",
        "    enc_col_test = enc.transform(X_val[[column]])\n",
        "    enc_X_test[feature_names] = pd.DataFrame.sparse.from_spmatrix(enc_col_test, columns=feature_names)\n",
        "  elif column in numeric_columns:\n",
        "    scaler = StandardScaler()\n",
        "    transformed_col_train = scaler.fit_transform(X_train[[column]])\n",
        "    enc_X_train[column] = transformed_col_train\n",
        "\n",
        "    transformed_col_val = scaler.transform(X_val[[column]])\n",
        "    enc_X_val[column] = transformed_col_val\n",
        "\n",
        "    transformed_col_test = scaler.transform(X_test[[column]])\n",
        "    enc_X_test[column] = transformed_col_test\n",
        "  elif column in boolean_columns:\n",
        "    enc_X_train[column] = X_train[[column]]\n",
        "    enc_X_val[column] = X_val[[column]]\n",
        "    enc_X_test[column] = X_test[[column]]\n",
        "\n",
        "for column in ordered_columns:\n",
        "    enc = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "    enc_col_train = enc.fit_transform(X_train[[column]])\n",
        "    enc_X_train[column] = enc_col_train\n",
        "\n",
        "    enc_col_val = enc.transform(X_val[[column]])\n",
        "    enc_X_val[column] = enc_col_val\n",
        "    \n",
        "    enc_col_test = enc.transform(X_test[[column]])\n",
        "    enc_X_test[column] = enc_col_test"
      ],
      "metadata": {
        "id": "506QPQxHY3TZ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "Nqqk0rwTE7LV",
        "outputId": "2de23737-5126-404f-fea6-0f52540c142c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   host_is_superhost  host_identity_verified  latitude  longitude  \\\n",
              "0                0.0                     1.0 -0.352883   0.355082   \n",
              "1                0.0                     1.0 -0.304823   0.240874   \n",
              "2                1.0                     1.0 -1.067570   1.000470   \n",
              "3                0.0                     1.0  1.754781  -1.753646   \n",
              "4                1.0                     1.0 -0.292896   0.254712   \n",
              "\n",
              "   room_type_Entire home/apt  room_type_Hotel room  room_type_Private room  \\\n",
              "0                        1.0                   0.0                     0.0   \n",
              "1                        0.0                   0.0                     1.0   \n",
              "2                        1.0                   0.0                     0.0   \n",
              "3                        1.0                   0.0                     0.0   \n",
              "4                        1.0                   0.0                     0.0   \n",
              "\n",
              "   room_type_Shared room  accommodates  bedrooms      beds  minimum_nights  \\\n",
              "0                    0.0      1.015209  1.180123  0.412326       -0.368554   \n",
              "1                    0.0     -0.029406  0.279666 -0.152200        0.492833   \n",
              "2                    0.0      2.059824  1.180123  0.412326       -0.434815   \n",
              "3                    0.0      1.363414  2.080580  1.541379       -0.401685   \n",
              "4                    0.0     -0.725817 -0.620791 -0.716726       -0.467945   \n",
              "\n",
              "   maximum_nights  availability_30  number_of_reviews  instant_bookable  \\\n",
              "0       -0.048206         0.319855          -0.512596                 1   \n",
              "1        0.130383        -1.010235           0.048695                 0   \n",
              "2       -0.127396         0.497201          -0.288079                 1   \n",
              "3       -0.127396         0.319855          -0.525069                 1   \n",
              "4       -0.126926        -0.832889          -0.213240                 0   \n",
              "\n",
              "   reviews_per_month  state_Los Angeles  state_Oakland  state_Pacific Grove  \\\n",
              "0          -0.190145                1.0            0.0                  0.0   \n",
              "1          -0.423814                1.0            0.0                  0.0   \n",
              "2           0.831479                0.0            0.0                  0.0   \n",
              "3          -0.733562                0.0            0.0                  0.0   \n",
              "4           1.505316                1.0            0.0                  0.0   \n",
              "\n",
              "   state_San Diego  state_San Francisco  state_San Mateo County  \\\n",
              "0              0.0                  0.0                     0.0   \n",
              "1              0.0                  0.0                     0.0   \n",
              "2              1.0                  0.0                     0.0   \n",
              "3              0.0                  1.0                     0.0   \n",
              "4              0.0                  0.0                     0.0   \n",
              "\n",
              "   state_Santa Clara County  state_Santa Cruz County  has_license  bathrooms  \\\n",
              "0                       0.0                      0.0            0   0.430007   \n",
              "1                       0.0                      0.0            1   0.430007   \n",
              "2                       0.0                      0.0            0   0.430007   \n",
              "3                       0.0                      0.0            1   0.430007   \n",
              "4                       0.0                      0.0            1  -0.558052   \n",
              "\n",
              "   bathroom_type_NA  bathroom_type_bath  bathroom_type_baths  \\\n",
              "0               0.0                 0.0                  1.0   \n",
              "1               0.0                 0.0                  0.0   \n",
              "2               0.0                 0.0                  1.0   \n",
              "3               0.0                 0.0                  1.0   \n",
              "4               0.0                 1.0                  0.0   \n",
              "\n",
              "   bathroom_type_half-bath  bathroom_type_private  bathroom_type_shared  \\\n",
              "0                      0.0                    0.0                   0.0   \n",
              "1                      0.0                    0.0                   1.0   \n",
              "2                      0.0                    0.0                   0.0   \n",
              "3                      0.0                    0.0                   0.0   \n",
              "4                      0.0                    0.0                   0.0   \n",
              "\n",
              "   num_of_amenities  essentials    luxury  appliances   comfort  \\\n",
              "0          0.133493    1.032952 -0.784872    0.711204  0.774702   \n",
              "1         -0.342971   -1.010104  1.354526   -0.442271  0.774702   \n",
              "2          2.447745    1.032952 -0.071739    1.095696  0.774702   \n",
              "3          1.018354    1.032952  0.641393    0.711204  0.774702   \n",
              "4          0.405758    1.032952  0.641393   -0.826763  0.774702   \n",
              "\n",
              "   entertainment  security  furniture  miscellaneous  host_gender_female  \\\n",
              "0      -0.388282 -0.405614  -0.761956       0.025229                 0.0   \n",
              "1       0.885145 -0.405614  -0.761956      -0.432887                 1.0   \n",
              "2       0.885145  0.754637   3.625324       2.888454                 1.0   \n",
              "3       0.885145 -0.405614   1.870412       0.826932                 0.0   \n",
              "4      -0.388282 -0.405614   0.992956       0.483345                 0.0   \n",
              "\n",
              "   host_gender_male  host_gender_unknown  sentiment_mean_score  \\\n",
              "0               0.0                  1.0              0.734743   \n",
              "1               0.0                  0.0              0.868816   \n",
              "2               0.0                  0.0              0.724163   \n",
              "3               1.0                  0.0             -1.696726   \n",
              "4               0.0                  1.0              0.507710   \n",
              "\n",
              "   host_response_time  host_response_rate  host_acceptance_rate  \\\n",
              "0                 4.0                 2.0                   2.0   \n",
              "1                 0.0                 0.0                   0.0   \n",
              "2                 4.0                 1.0                   2.0   \n",
              "3                 4.0                 1.0                   2.0   \n",
              "4                 4.0                 1.0                   2.0   \n",
              "\n",
              "   review_scores_rating  description_sentiment  \\\n",
              "0                  21.0                    4.0   \n",
              "1                  30.0                    4.0   \n",
              "2                  30.0                    4.0   \n",
              "3                  31.0                    4.0   \n",
              "4                  30.0                    4.0   \n",
              "\n",
              "   neighborhood_overview_sentiment  \n",
              "0                              0.0  \n",
              "1                              2.0  \n",
              "2                              2.0  \n",
              "3                              2.0  \n",
              "4                              5.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11f2657e-006e-459f-85ed-fc510b58448a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>host_is_superhost</th>\n",
              "      <th>host_identity_verified</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>room_type_Entire home/apt</th>\n",
              "      <th>room_type_Hotel room</th>\n",
              "      <th>room_type_Private room</th>\n",
              "      <th>room_type_Shared room</th>\n",
              "      <th>accommodates</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>beds</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>maximum_nights</th>\n",
              "      <th>availability_30</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>instant_bookable</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>state_Los Angeles</th>\n",
              "      <th>state_Oakland</th>\n",
              "      <th>state_Pacific Grove</th>\n",
              "      <th>state_San Diego</th>\n",
              "      <th>state_San Francisco</th>\n",
              "      <th>state_San Mateo County</th>\n",
              "      <th>state_Santa Clara County</th>\n",
              "      <th>state_Santa Cruz County</th>\n",
              "      <th>has_license</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bathroom_type_NA</th>\n",
              "      <th>bathroom_type_bath</th>\n",
              "      <th>bathroom_type_baths</th>\n",
              "      <th>bathroom_type_half-bath</th>\n",
              "      <th>bathroom_type_private</th>\n",
              "      <th>bathroom_type_shared</th>\n",
              "      <th>num_of_amenities</th>\n",
              "      <th>essentials</th>\n",
              "      <th>luxury</th>\n",
              "      <th>appliances</th>\n",
              "      <th>comfort</th>\n",
              "      <th>entertainment</th>\n",
              "      <th>security</th>\n",
              "      <th>furniture</th>\n",
              "      <th>miscellaneous</th>\n",
              "      <th>host_gender_female</th>\n",
              "      <th>host_gender_male</th>\n",
              "      <th>host_gender_unknown</th>\n",
              "      <th>sentiment_mean_score</th>\n",
              "      <th>host_response_time</th>\n",
              "      <th>host_response_rate</th>\n",
              "      <th>host_acceptance_rate</th>\n",
              "      <th>review_scores_rating</th>\n",
              "      <th>description_sentiment</th>\n",
              "      <th>neighborhood_overview_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.352883</td>\n",
              "      <td>0.355082</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.015209</td>\n",
              "      <td>1.180123</td>\n",
              "      <td>0.412326</td>\n",
              "      <td>-0.368554</td>\n",
              "      <td>-0.048206</td>\n",
              "      <td>0.319855</td>\n",
              "      <td>-0.512596</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.190145</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.430007</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.133493</td>\n",
              "      <td>1.032952</td>\n",
              "      <td>-0.784872</td>\n",
              "      <td>0.711204</td>\n",
              "      <td>0.774702</td>\n",
              "      <td>-0.388282</td>\n",
              "      <td>-0.405614</td>\n",
              "      <td>-0.761956</td>\n",
              "      <td>0.025229</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.734743</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.304823</td>\n",
              "      <td>0.240874</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.029406</td>\n",
              "      <td>0.279666</td>\n",
              "      <td>-0.152200</td>\n",
              "      <td>0.492833</td>\n",
              "      <td>0.130383</td>\n",
              "      <td>-1.010235</td>\n",
              "      <td>0.048695</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.423814</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.430007</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.342971</td>\n",
              "      <td>-1.010104</td>\n",
              "      <td>1.354526</td>\n",
              "      <td>-0.442271</td>\n",
              "      <td>0.774702</td>\n",
              "      <td>0.885145</td>\n",
              "      <td>-0.405614</td>\n",
              "      <td>-0.761956</td>\n",
              "      <td>-0.432887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.868816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.067570</td>\n",
              "      <td>1.000470</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.059824</td>\n",
              "      <td>1.180123</td>\n",
              "      <td>0.412326</td>\n",
              "      <td>-0.434815</td>\n",
              "      <td>-0.127396</td>\n",
              "      <td>0.497201</td>\n",
              "      <td>-0.288079</td>\n",
              "      <td>1</td>\n",
              "      <td>0.831479</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.430007</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.447745</td>\n",
              "      <td>1.032952</td>\n",
              "      <td>-0.071739</td>\n",
              "      <td>1.095696</td>\n",
              "      <td>0.774702</td>\n",
              "      <td>0.885145</td>\n",
              "      <td>0.754637</td>\n",
              "      <td>3.625324</td>\n",
              "      <td>2.888454</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.724163</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.754781</td>\n",
              "      <td>-1.753646</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.363414</td>\n",
              "      <td>2.080580</td>\n",
              "      <td>1.541379</td>\n",
              "      <td>-0.401685</td>\n",
              "      <td>-0.127396</td>\n",
              "      <td>0.319855</td>\n",
              "      <td>-0.525069</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.733562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.430007</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.018354</td>\n",
              "      <td>1.032952</td>\n",
              "      <td>0.641393</td>\n",
              "      <td>0.711204</td>\n",
              "      <td>0.774702</td>\n",
              "      <td>0.885145</td>\n",
              "      <td>-0.405614</td>\n",
              "      <td>1.870412</td>\n",
              "      <td>0.826932</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.696726</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.292896</td>\n",
              "      <td>0.254712</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.725817</td>\n",
              "      <td>-0.620791</td>\n",
              "      <td>-0.716726</td>\n",
              "      <td>-0.467945</td>\n",
              "      <td>-0.126926</td>\n",
              "      <td>-0.832889</td>\n",
              "      <td>-0.213240</td>\n",
              "      <td>0</td>\n",
              "      <td>1.505316</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.558052</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.405758</td>\n",
              "      <td>1.032952</td>\n",
              "      <td>0.641393</td>\n",
              "      <td>-0.826763</td>\n",
              "      <td>0.774702</td>\n",
              "      <td>-0.388282</td>\n",
              "      <td>-0.405614</td>\n",
              "      <td>0.992956</td>\n",
              "      <td>0.483345</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.507710</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11f2657e-006e-459f-85ed-fc510b58448a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11f2657e-006e-459f-85ed-fc510b58448a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11f2657e-006e-459f-85ed-fc510b58448a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiouH7StFCAR",
        "outputId": "7d2d513b-b134-4a0f-a8ed-a8f015196faf"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56423, 52)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization\n",
        "\n",
        "model1 = Sequential([\n",
        "    Input(shape=(enc_X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model1.compile(optimizer='adam', \n",
        "              loss='mae',\n",
        "              metrics=['mae', 'mse'])"
      ],
      "metadata": {
        "id": "RKcKoV26FJOm"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sXA49zAFV-H",
        "outputId": "4973da02-e962-4e00-867f-1e606b134a95"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 32)                1696      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,729\n",
            "Trainable params: 1,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "STEPS = X_train.shape[0] // BATCH_SIZE\n",
        "\n",
        "history = model1.fit(\n",
        "  enc_X_train, y_train,\n",
        "  validation_data=(enc_X_val, y_val),\n",
        "  steps_per_epoch = STEPS,\n",
        "  batch_size = BATCH_SIZE,\n",
        "  epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWuLER5TFZy5",
        "outputId": "3555ec8f-ad90-4ece-b98a-d581ed9c79c2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 246.5356 - mae: 246.5356 - mse: 614311.5625 - val_loss: 199.5365 - val_mae: 199.5365 - val_mse: 580664.3750\n",
            "Epoch 2/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 178.4994 - mae: 178.4994 - mse: 565566.8750 - val_loss: 171.9958 - val_mae: 171.9958 - val_mse: 549035.2500\n",
            "Epoch 3/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 163.4076 - mae: 163.4076 - mse: 540617.4375 - val_loss: 160.3894 - val_mae: 160.3894 - val_mse: 536698.1875\n",
            "Epoch 4/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 153.1960 - mae: 153.1960 - mse: 531569.9375 - val_loss: 152.0602 - val_mae: 152.0602 - val_mse: 525134.0000\n",
            "Epoch 5/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 147.2234 - mae: 147.2234 - mse: 534879.3750 - val_loss: 147.5385 - val_mae: 147.5385 - val_mse: 516993.9375\n",
            "Epoch 6/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 142.6203 - mae: 142.6203 - mse: 523215.2188 - val_loss: 145.5450 - val_mae: 145.5450 - val_mse: 511568.9688\n",
            "Epoch 7/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 141.3292 - mae: 141.3292 - mse: 517203.6250 - val_loss: 144.4471 - val_mae: 144.4471 - val_mse: 507961.2188\n",
            "Epoch 8/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 139.8420 - mae: 139.8420 - mse: 505867.0625 - val_loss: 143.5937 - val_mae: 143.5937 - val_mse: 505539.7188\n",
            "Epoch 9/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 139.7372 - mae: 139.7372 - mse: 522706.6250 - val_loss: 142.8575 - val_mae: 142.8575 - val_mse: 503584.1562\n",
            "Epoch 10/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 138.7925 - mae: 138.7925 - mse: 509442.8750 - val_loss: 142.3115 - val_mae: 142.3115 - val_mse: 502800.0625\n",
            "Epoch 11/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 137.8188 - mae: 137.8188 - mse: 498803.0625 - val_loss: 141.5426 - val_mae: 141.5426 - val_mse: 499991.1562\n",
            "Epoch 12/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 137.0984 - mae: 137.0984 - mse: 510877.3750 - val_loss: 140.9340 - val_mae: 140.9340 - val_mse: 498183.3125\n",
            "Epoch 13/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 136.9404 - mae: 136.9404 - mse: 505255.4688 - val_loss: 140.3613 - val_mae: 140.3613 - val_mse: 496231.8438\n",
            "Epoch 14/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 134.0192 - mae: 134.0192 - mse: 470629.2812 - val_loss: 139.7802 - val_mae: 139.7802 - val_mse: 495091.0938\n",
            "Epoch 15/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 137.9532 - mae: 137.9532 - mse: 533520.4375 - val_loss: 139.2807 - val_mae: 139.2807 - val_mse: 493180.4062\n",
            "Epoch 16/50\n",
            "220/220 [==============================] - 2s 11ms/step - loss: 134.3868 - mae: 134.3868 - mse: 491345.4375 - val_loss: 138.7821 - val_mae: 138.7821 - val_mse: 492129.6875\n",
            "Epoch 17/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 134.6020 - mae: 134.6020 - mse: 489651.4688 - val_loss: 138.3117 - val_mae: 138.3117 - val_mse: 490927.2188\n",
            "Epoch 18/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 133.1755 - mae: 133.1755 - mse: 482837.0000 - val_loss: 137.9181 - val_mae: 137.9181 - val_mse: 489600.0938\n",
            "Epoch 19/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 134.4931 - mae: 134.4931 - mse: 528380.8125 - val_loss: 137.4173 - val_mae: 137.4173 - val_mse: 487956.2500\n",
            "Epoch 20/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 131.7847 - mae: 131.7847 - mse: 467070.6250 - val_loss: 136.9884 - val_mae: 136.9884 - val_mse: 486511.2812\n",
            "Epoch 21/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 135.2488 - mae: 135.2488 - mse: 535497.0000 - val_loss: 136.5312 - val_mae: 136.5312 - val_mse: 485148.7812\n",
            "Epoch 22/50\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 131.8062 - mae: 131.8062 - mse: 495343.1875 - val_loss: 136.0875 - val_mae: 136.0875 - val_mse: 484351.4375\n",
            "Epoch 23/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 131.1929 - mae: 131.1929 - mse: 482886.6250 - val_loss: 135.7053 - val_mae: 135.7053 - val_mse: 483655.8750\n",
            "Epoch 24/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 131.1562 - mae: 131.1562 - mse: 483166.4062 - val_loss: 135.3211 - val_mae: 135.3211 - val_mse: 481808.7188\n",
            "Epoch 25/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 129.5943 - mae: 129.5943 - mse: 481276.6562 - val_loss: 134.9176 - val_mae: 134.9176 - val_mse: 481987.3438\n",
            "Epoch 26/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 130.6661 - mae: 130.6661 - mse: 478901.7812 - val_loss: 134.6552 - val_mae: 134.6552 - val_mse: 479971.7188\n",
            "Epoch 27/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 130.8923 - mae: 130.8923 - mse: 500188.8125 - val_loss: 134.2204 - val_mae: 134.2204 - val_mse: 479412.5938\n",
            "Epoch 28/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 129.2395 - mae: 129.2395 - mse: 471239.5938 - val_loss: 133.9128 - val_mae: 133.9128 - val_mse: 479227.0938\n",
            "Epoch 29/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 131.1454 - mae: 131.1454 - mse: 523339.5938 - val_loss: 133.5749 - val_mae: 133.5749 - val_mse: 477770.0312\n",
            "Epoch 30/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 130.1539 - mae: 130.1539 - mse: 485853.8125 - val_loss: 133.3212 - val_mae: 133.3212 - val_mse: 477854.5938\n",
            "Epoch 31/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 126.4798 - mae: 126.4798 - mse: 456868.0000 - val_loss: 133.0245 - val_mae: 133.0245 - val_mse: 476437.9062\n",
            "Epoch 32/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 129.3803 - mae: 129.3803 - mse: 477384.6562 - val_loss: 132.7708 - val_mae: 132.7708 - val_mse: 476138.8750\n",
            "Epoch 33/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 130.1956 - mae: 130.1956 - mse: 523979.1875 - val_loss: 132.5384 - val_mae: 132.5384 - val_mse: 474416.1562\n",
            "Epoch 34/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 126.8037 - mae: 126.8037 - mse: 466925.1562 - val_loss: 132.3206 - val_mae: 132.3206 - val_mse: 475083.7188\n",
            "Epoch 35/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 127.4547 - mae: 127.4547 - mse: 474636.3750 - val_loss: 132.0998 - val_mae: 132.0998 - val_mse: 473359.2500\n",
            "Epoch 36/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 125.6118 - mae: 125.6118 - mse: 438077.2812 - val_loss: 131.9157 - val_mae: 131.9157 - val_mse: 473837.0625\n",
            "Epoch 37/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 130.9095 - mae: 130.9095 - mse: 541239.6250 - val_loss: 131.6552 - val_mae: 131.6552 - val_mse: 472460.1562\n",
            "Epoch 38/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 126.9212 - mae: 126.9212 - mse: 469864.6562 - val_loss: 131.5066 - val_mae: 131.5066 - val_mse: 472066.1562\n",
            "Epoch 39/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 126.8113 - mae: 126.8113 - mse: 490947.9688 - val_loss: 131.2595 - val_mae: 131.2595 - val_mse: 470292.8125\n",
            "Epoch 40/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 124.1495 - mae: 124.1495 - mse: 433879.0000 - val_loss: 131.1038 - val_mae: 131.1038 - val_mse: 470878.4375\n",
            "Epoch 41/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 129.7464 - mae: 129.7464 - mse: 535890.1250 - val_loss: 130.8538 - val_mae: 130.8538 - val_mse: 468667.3438\n",
            "Epoch 42/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 126.7369 - mae: 126.7369 - mse: 461118.7812 - val_loss: 130.6894 - val_mae: 130.6894 - val_mse: 468477.8438\n",
            "Epoch 43/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 125.5278 - mae: 125.5278 - mse: 475924.4062 - val_loss: 130.5386 - val_mae: 130.5386 - val_mse: 468491.3125\n",
            "Epoch 44/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 127.4367 - mae: 127.4367 - mse: 479497.9375 - val_loss: 130.4473 - val_mae: 130.4473 - val_mse: 466360.9375\n",
            "Epoch 45/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 124.1208 - mae: 124.1208 - mse: 466410.2188 - val_loss: 130.1893 - val_mae: 130.1893 - val_mse: 466880.9062\n",
            "Epoch 46/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 130.3130 - mae: 130.3130 - mse: 525456.0000 - val_loss: 130.0927 - val_mae: 130.0927 - val_mse: 466652.6250\n",
            "Epoch 47/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 122.9866 - mae: 122.9866 - mse: 433546.0312 - val_loss: 129.9519 - val_mae: 129.9519 - val_mse: 465366.7188\n",
            "Epoch 48/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 125.0085 - mae: 125.0085 - mse: 456141.8125 - val_loss: 129.7841 - val_mae: 129.7841 - val_mse: 465178.1562\n",
            "Epoch 49/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 126.7389 - mae: 126.7389 - mse: 505623.5938 - val_loss: 129.6797 - val_mae: 129.6797 - val_mse: 464665.6875\n",
            "Epoch 50/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 124.0533 - mae: 124.0533 - mse: 451469.7812 - val_loss: 129.5491 - val_mae: 129.5491 - val_mse: 464604.2812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "y_pred = model1.predict(enc_X_val)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "r2_square = r2_score(y_val, y_pred)\n",
        "print('\\nMAE:', mae)\n",
        "print('\\nMSE:', mse)\n",
        "print('\\nRMSE:', rmse)\n",
        "print('\\nR2 Square', r2_square)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1ZiLXspFntC",
        "outputId": "b01969ba-fd1b-417b-c267-5428a0fa6edf"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "378/378 [==============================] - 1s 1ms/step\n",
            "\n",
            "MAE: 129.54906219706348\n",
            "\n",
            "MSE: 464604.3284060094\n",
            "\n",
            "RMSE: 681.6189026178847\n",
            "\n",
            "R2 Square 0.15403280828148302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log-Price vs Price"
      ],
      "metadata": {
        "id": "WpLfSJgkGKkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_y_train = np.log(y_train)\n",
        "log_y_val = np.log(y_val)"
      ],
      "metadata": {
        "id": "m-saiFYNGUrj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(\n",
        "  enc_X_train, log_y_train,\n",
        "  validation_data=(enc_X_val, log_y_val),\n",
        "  steps_per_epoch = STEPS,\n",
        "  batch_size = BATCH_SIZE,\n",
        "  epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqLfX-WKIeiR",
        "outputId": "87739b27-5392-4ca7-9015-6b6cd3505ca5"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 39.8967 - mae: 39.8967 - mse: 12641.9404 - val_loss: 14.7391 - val_mae: 14.7391 - val_mse: 2290.9050\n",
            "Epoch 2/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 11.8506 - mae: 11.8506 - mse: 1972.2496 - val_loss: 9.0944 - val_mae: 9.0944 - val_mse: 929.8691\n",
            "Epoch 3/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 7.7778 - mae: 7.7778 - mse: 1036.2025 - val_loss: 6.1171 - val_mae: 6.1171 - val_mse: 497.4693\n",
            "Epoch 4/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 5.2324 - mae: 5.2324 - mse: 647.3768 - val_loss: 4.2019 - val_mae: 4.2019 - val_mse: 304.6725\n",
            "Epoch 5/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 3.7192 - mae: 3.7192 - mse: 425.7533 - val_loss: 3.1659 - val_mae: 3.1659 - val_mse: 199.6232\n",
            "Epoch 6/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 2.9255 - mae: 2.9255 - mse: 437.2571 - val_loss: 2.5331 - val_mae: 2.5331 - val_mse: 137.2053\n",
            "Epoch 7/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 2.3264 - mae: 2.3264 - mse: 286.5157 - val_loss: 2.0332 - val_mae: 2.0332 - val_mse: 98.0664\n",
            "Epoch 8/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 1.9204 - mae: 1.9204 - mse: 215.2155 - val_loss: 1.7294 - val_mae: 1.7294 - val_mse: 73.5547\n",
            "Epoch 9/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 1.6711 - mae: 1.6711 - mse: 210.7526 - val_loss: 1.4876 - val_mae: 1.4876 - val_mse: 56.5868\n",
            "Epoch 10/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 1.4650 - mae: 1.4650 - mse: 173.2396 - val_loss: 1.3031 - val_mae: 1.3031 - val_mse: 44.0389\n",
            "Epoch 11/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 1.2683 - mae: 1.2683 - mse: 150.3236 - val_loss: 1.1482 - val_mae: 1.1482 - val_mse: 36.0597\n",
            "Epoch 12/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 1.1513 - mae: 1.1513 - mse: 133.7532 - val_loss: 1.0448 - val_mae: 1.0448 - val_mse: 29.5110\n",
            "Epoch 13/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 1.0346 - mae: 1.0346 - mse: 117.7585 - val_loss: 0.9373 - val_mae: 0.9373 - val_mse: 24.8342\n",
            "Epoch 14/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.9442 - mae: 0.9442 - mse: 107.6340 - val_loss: 0.8598 - val_mae: 0.8598 - val_mse: 21.0144\n",
            "Epoch 15/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.8629 - mae: 0.8629 - mse: 99.0841 - val_loss: 0.7871 - val_mae: 0.7871 - val_mse: 18.0186\n",
            "Epoch 16/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.7681 - mae: 0.7681 - mse: 61.3780 - val_loss: 0.7286 - val_mae: 0.7286 - val_mse: 15.6094\n",
            "Epoch 17/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.7750 - mae: 0.7750 - mse: 108.5978 - val_loss: 0.7304 - val_mae: 0.7304 - val_mse: 13.2177\n",
            "Epoch 18/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.7003 - mae: 0.7003 - mse: 74.3395 - val_loss: 0.6535 - val_mae: 0.6535 - val_mse: 11.3124\n",
            "Epoch 19/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.6639 - mae: 0.6639 - mse: 65.0236 - val_loss: 0.6132 - val_mae: 0.6132 - val_mse: 9.9232\n",
            "Epoch 20/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.6350 - mae: 0.6350 - mse: 66.9157 - val_loss: 0.5915 - val_mae: 0.5915 - val_mse: 8.7887\n",
            "Epoch 21/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.5961 - mae: 0.5961 - mse: 40.4080 - val_loss: 0.5664 - val_mae: 0.5664 - val_mse: 7.8525\n",
            "Epoch 22/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.6135 - mae: 0.6135 - mse: 69.4294 - val_loss: 0.5632 - val_mae: 0.5632 - val_mse: 6.9110\n",
            "Epoch 23/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.5798 - mae: 0.5798 - mse: 50.8492 - val_loss: 0.5480 - val_mae: 0.5480 - val_mse: 6.1738\n",
            "Epoch 24/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.5644 - mae: 0.5644 - mse: 50.3971 - val_loss: 0.5429 - val_mae: 0.5429 - val_mse: 5.5220\n",
            "Epoch 25/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.5501 - mae: 0.5501 - mse: 44.1696 - val_loss: 0.5497 - val_mae: 0.5497 - val_mse: 4.9700\n",
            "Epoch 26/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.5353 - mae: 0.5353 - mse: 41.8442 - val_loss: 0.5463 - val_mae: 0.5463 - val_mse: 4.4338\n",
            "Epoch 27/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.5296 - mae: 0.5296 - mse: 38.8128 - val_loss: 0.5009 - val_mae: 0.5009 - val_mse: 3.9706\n",
            "Epoch 28/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.5203 - mae: 0.5203 - mse: 37.2339 - val_loss: 0.4973 - val_mae: 0.4973 - val_mse: 3.4931\n",
            "Epoch 29/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.5051 - mae: 0.5051 - mse: 34.5207 - val_loss: 0.4896 - val_mae: 0.4896 - val_mse: 3.1599\n",
            "Epoch 30/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.5031 - mae: 0.5031 - mse: 32.4795 - val_loss: 0.4838 - val_mae: 0.4838 - val_mse: 2.8290\n",
            "Epoch 31/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4859 - mae: 0.4859 - mse: 29.6878 - val_loss: 0.5004 - val_mae: 0.5004 - val_mse: 2.6329\n",
            "Epoch 32/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.4939 - mae: 0.4939 - mse: 30.7934 - val_loss: 0.4768 - val_mae: 0.4768 - val_mse: 2.3344\n",
            "Epoch 33/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4792 - mae: 0.4792 - mse: 27.6238 - val_loss: 0.4645 - val_mae: 0.4645 - val_mse: 2.1336\n",
            "Epoch 34/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4746 - mae: 0.4746 - mse: 26.2959 - val_loss: 0.4659 - val_mae: 0.4659 - val_mse: 1.9665\n",
            "Epoch 35/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4720 - mae: 0.4720 - mse: 24.9073 - val_loss: 0.4585 - val_mae: 0.4585 - val_mse: 1.8302\n",
            "Epoch 36/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4521 - mae: 0.4521 - mse: 6.5505 - val_loss: 0.4500 - val_mae: 0.4500 - val_mse: 1.6758\n",
            "Epoch 37/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4872 - mae: 0.4872 - mse: 39.9631 - val_loss: 0.4730 - val_mae: 0.4730 - val_mse: 1.5559\n",
            "Epoch 38/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4588 - mae: 0.4588 - mse: 20.5736 - val_loss: 0.4458 - val_mae: 0.4458 - val_mse: 1.5076\n",
            "Epoch 39/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4574 - mae: 0.4574 - mse: 17.2058 - val_loss: 0.4696 - val_mae: 0.4696 - val_mse: 1.4820\n",
            "Epoch 40/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4714 - mae: 0.4714 - mse: 22.5360 - val_loss: 0.4482 - val_mae: 0.4482 - val_mse: 1.4016\n",
            "Epoch 41/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4521 - mae: 0.4521 - mse: 17.5539 - val_loss: 0.4412 - val_mae: 0.4412 - val_mse: 1.3689\n",
            "Epoch 42/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.4523 - mae: 0.4523 - mse: 16.4893 - val_loss: 0.4402 - val_mae: 0.4402 - val_mse: 1.3108\n",
            "Epoch 43/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4461 - mae: 0.4461 - mse: 15.1554 - val_loss: 0.4478 - val_mae: 0.4478 - val_mse: 1.3007\n",
            "Epoch 44/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.4508 - mae: 0.4508 - mse: 14.2926 - val_loss: 0.4390 - val_mae: 0.4390 - val_mse: 1.2843\n",
            "Epoch 45/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.4473 - mae: 0.4473 - mse: 13.2601 - val_loss: 0.4368 - val_mae: 0.4368 - val_mse: 1.2292\n",
            "Epoch 46/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.4346 - mae: 0.4346 - mse: 12.0960 - val_loss: 0.4321 - val_mae: 0.4321 - val_mse: 1.2051\n",
            "Epoch 47/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4396 - mae: 0.4396 - mse: 11.1353 - val_loss: 0.4383 - val_mae: 0.4383 - val_mse: 1.1852\n",
            "Epoch 48/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.4392 - mae: 0.4392 - mse: 11.1565 - val_loss: 0.4420 - val_mae: 0.4420 - val_mse: 1.1966\n",
            "Epoch 49/50\n",
            "220/220 [==============================] - 1s 2ms/step - loss: 0.4241 - mae: 0.4241 - mse: 1.5232 - val_loss: 0.4353 - val_mae: 0.4353 - val_mse: 1.1675\n",
            "Epoch 50/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 0.4449 - mae: 0.4449 - mse: 16.8475 - val_loss: 0.4370 - val_mae: 0.4370 - val_mse: 1.1547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_y_pred = model1.predict(enc_X_val)\n",
        "mae = mean_absolute_error(log_y_val, log_y_pred)\n",
        "mse = mean_squared_error(log_y_val, log_y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(log_y_val, log_y_pred))\n",
        "r2_square = r2_score(log_y_val, log_y_pred)\n",
        "print('\\nMAE:', mae)\n",
        "print('\\nMSE:', mse)\n",
        "print('\\nRMSE:', rmse)\n",
        "print('\\nR2 Square', r2_square)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjgIxydZIuHJ",
        "outputId": "895aee27-0bcc-441c-8a56-ddf14a24c1f9"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "378/378 [==============================] - 0s 1ms/step\n",
            "\n",
            "MAE: 0.4370185998041734\n",
            "\n",
            "MSE: 1.1546995696528966\n",
            "\n",
            "RMSE: 1.0745694810727209\n",
            "\n",
            "R2 Square -0.5610477444052846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems like log-price does not perform as well as price."
      ],
      "metadata": {
        "id": "x7gPSdmVS1kw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning: Number of Nodes\n",
        "## 256 Nodes"
      ],
      "metadata": {
        "id": "JEqy1qJ6QtF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "    Input(shape=(enc_X_train.shape[1],)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model2.compile(optimizer='adam', \n",
        "              loss='mae',\n",
        "              metrics=['mae', 'mse'])"
      ],
      "metadata": {
        "id": "_qrj2I1vQn26"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJFId1Y0Q62k",
        "outputId": "52897760-ba3c-4898-f58e-9cf8bf50d105"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 256)               13568     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,825\n",
            "Trainable params: 13,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(\n",
        "  enc_X_train, y_train,\n",
        "  validation_data=(enc_X_val, y_val),\n",
        "  steps_per_epoch = STEPS,\n",
        "  batch_size = BATCH_SIZE,\n",
        "  epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzsetgLqQ80C",
        "outputId": "eb989882-3d91-4016-e387-753a91e567c3"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 201.4284 - mae: 201.4284 - mse: 581713.6875 - val_loss: 165.4040 - val_mae: 165.4040 - val_mse: 541504.3750\n",
            "Epoch 2/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 150.6233 - mae: 150.6233 - mse: 533879.6875 - val_loss: 146.0935 - val_mae: 146.0935 - val_mse: 513670.9688\n",
            "Epoch 3/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 139.5553 - mae: 139.5553 - mse: 496174.2188 - val_loss: 142.4961 - val_mae: 142.4961 - val_mse: 504694.0000\n",
            "Epoch 4/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 137.5442 - mae: 137.5442 - mse: 512479.5312 - val_loss: 140.1945 - val_mae: 140.1945 - val_mse: 499339.0625\n",
            "Epoch 5/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 135.6386 - mae: 135.6386 - mse: 509259.9375 - val_loss: 138.3632 - val_mae: 138.3632 - val_mse: 494945.6562\n",
            "Epoch 6/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 133.5324 - mae: 133.5324 - mse: 501254.8125 - val_loss: 137.0283 - val_mae: 137.0283 - val_mse: 487991.9688\n",
            "Epoch 7/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 132.8145 - mae: 132.8145 - mse: 507400.3125 - val_loss: 135.5835 - val_mae: 135.5835 - val_mse: 485477.4062\n",
            "Epoch 8/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 130.0574 - mae: 130.0574 - mse: 479991.0938 - val_loss: 134.2715 - val_mae: 134.2715 - val_mse: 483316.1562\n",
            "Epoch 9/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 128.6956 - mae: 128.6956 - mse: 479960.5938 - val_loss: 133.2982 - val_mae: 133.2982 - val_mse: 480238.3750\n",
            "Epoch 10/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 130.5927 - mae: 130.5927 - mse: 505839.0938 - val_loss: 132.4146 - val_mae: 132.4146 - val_mse: 477816.0000\n",
            "Epoch 11/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 126.8281 - mae: 126.8281 - mse: 467626.0625 - val_loss: 131.7543 - val_mae: 131.7543 - val_mse: 475556.0312\n",
            "Epoch 12/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 127.9081 - mae: 127.9081 - mse: 491949.5625 - val_loss: 131.1886 - val_mae: 131.1886 - val_mse: 472393.5312\n",
            "Epoch 13/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 127.3209 - mae: 127.3209 - mse: 500471.1875 - val_loss: 130.4778 - val_mae: 130.4778 - val_mse: 472249.9062\n",
            "Epoch 14/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 124.4215 - mae: 124.4215 - mse: 452707.8125 - val_loss: 129.8816 - val_mae: 129.8816 - val_mse: 468628.1562\n",
            "Epoch 15/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 125.8033 - mae: 125.8033 - mse: 488202.8125 - val_loss: 129.5147 - val_mae: 129.5147 - val_mse: 466164.9375\n",
            "Epoch 16/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 124.9715 - mae: 124.9715 - mse: 488084.4375 - val_loss: 128.9437 - val_mae: 128.9437 - val_mse: 465636.5938\n",
            "Epoch 17/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 124.2885 - mae: 124.2885 - mse: 457536.1875 - val_loss: 128.5234 - val_mae: 128.5234 - val_mse: 463423.1875\n",
            "Epoch 18/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 124.6550 - mae: 124.6550 - mse: 491045.4688 - val_loss: 128.1457 - val_mae: 128.1457 - val_mse: 463947.2188\n",
            "Epoch 19/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 122.8425 - mae: 122.8425 - mse: 449383.7500 - val_loss: 127.7562 - val_mae: 127.7562 - val_mse: 461819.1250\n",
            "Epoch 20/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 123.7122 - mae: 123.7122 - mse: 485581.6562 - val_loss: 127.3971 - val_mae: 127.3971 - val_mse: 460238.0312\n",
            "Epoch 21/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 124.3958 - mae: 124.3958 - mse: 496213.8438 - val_loss: 127.0499 - val_mae: 127.0499 - val_mse: 458502.3438\n",
            "Epoch 22/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 121.5297 - mae: 121.5297 - mse: 443919.3750 - val_loss: 126.7578 - val_mae: 126.7578 - val_mse: 458204.6875\n",
            "Epoch 23/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 121.6421 - mae: 121.6421 - mse: 455162.7500 - val_loss: 126.7117 - val_mae: 126.7117 - val_mse: 456758.7500\n",
            "Epoch 24/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 121.9416 - mae: 121.9416 - mse: 486101.7812 - val_loss: 126.2358 - val_mae: 126.2358 - val_mse: 456681.1875\n",
            "Epoch 25/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 121.8042 - mae: 121.8042 - mse: 458340.6875 - val_loss: 126.0408 - val_mae: 126.0408 - val_mse: 453648.4375\n",
            "Epoch 26/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 123.2418 - mae: 123.2418 - mse: 494571.7812 - val_loss: 125.7316 - val_mae: 125.7316 - val_mse: 453883.0938\n",
            "Epoch 27/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 118.7022 - mae: 118.7022 - mse: 413957.4375 - val_loss: 125.5940 - val_mae: 125.5940 - val_mse: 453643.3438\n",
            "Epoch 28/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 121.7088 - mae: 121.7088 - mse: 483226.6250 - val_loss: 125.4170 - val_mae: 125.4170 - val_mse: 453001.6562\n",
            "Epoch 29/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 121.3574 - mae: 121.3574 - mse: 481702.0312 - val_loss: 125.1147 - val_mae: 125.1147 - val_mse: 452001.0938\n",
            "Epoch 30/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 121.5047 - mae: 121.5047 - mse: 458477.3750 - val_loss: 124.8161 - val_mae: 124.8161 - val_mse: 449748.6562\n",
            "Epoch 31/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 118.7000 - mae: 118.7000 - mse: 443483.1250 - val_loss: 124.7430 - val_mae: 124.7430 - val_mse: 449531.3750\n",
            "Epoch 32/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 121.1952 - mae: 121.1952 - mse: 475081.3750 - val_loss: 124.4770 - val_mae: 124.4770 - val_mse: 448786.3438\n",
            "Epoch 33/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 119.7141 - mae: 119.7141 - mse: 463289.8125 - val_loss: 124.3164 - val_mae: 124.3164 - val_mse: 447786.8750\n",
            "Epoch 34/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 119.4156 - mae: 119.4156 - mse: 448938.1250 - val_loss: 124.3170 - val_mae: 124.3170 - val_mse: 448167.9062\n",
            "Epoch 35/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 119.8045 - mae: 119.8045 - mse: 458733.2500 - val_loss: 123.9976 - val_mae: 123.9976 - val_mse: 445595.1875\n",
            "Epoch 36/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 120.2231 - mae: 120.2231 - mse: 483490.8438 - val_loss: 123.7961 - val_mae: 123.7961 - val_mse: 445203.7500\n",
            "Epoch 37/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 119.3434 - mae: 119.3434 - mse: 450763.4688 - val_loss: 123.6728 - val_mae: 123.6728 - val_mse: 445456.8125\n",
            "Epoch 38/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 119.1844 - mae: 119.1844 - mse: 473018.5625 - val_loss: 123.5288 - val_mae: 123.5288 - val_mse: 445972.7812\n",
            "Epoch 39/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 118.7169 - mae: 118.7169 - mse: 446865.2500 - val_loss: 123.4872 - val_mae: 123.4872 - val_mse: 445869.4688\n",
            "Epoch 40/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 114.3137 - mae: 114.3137 - mse: 394491.0312 - val_loss: 123.4575 - val_mae: 123.4575 - val_mse: 444565.6562\n",
            "Epoch 41/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 124.2580 - mae: 124.2580 - mse: 547461.1875 - val_loss: 123.1352 - val_mae: 123.1352 - val_mse: 443366.1250\n",
            "Epoch 42/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 118.6085 - mae: 118.6085 - mse: 446727.3750 - val_loss: 123.1694 - val_mae: 123.1694 - val_mse: 443863.2500\n",
            "Epoch 43/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 116.6830 - mae: 116.6830 - mse: 434677.6562 - val_loss: 123.1076 - val_mae: 123.1076 - val_mse: 440129.2188\n",
            "Epoch 44/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 120.7489 - mae: 120.7489 - mse: 506402.9375 - val_loss: 122.8124 - val_mae: 122.8124 - val_mse: 440787.5312\n",
            "Epoch 45/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 115.1647 - mae: 115.1647 - mse: 392213.7188 - val_loss: 122.6703 - val_mae: 122.6703 - val_mse: 441074.3438\n",
            "Epoch 46/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 120.9303 - mae: 120.9303 - mse: 488393.3125 - val_loss: 122.5016 - val_mae: 122.5016 - val_mse: 442275.0938\n",
            "Epoch 47/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 115.6459 - mae: 115.6459 - mse: 443718.7188 - val_loss: 122.5481 - val_mae: 122.5481 - val_mse: 441140.4062\n",
            "Epoch 48/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 117.5996 - mae: 117.5996 - mse: 435220.4688 - val_loss: 122.3846 - val_mae: 122.3846 - val_mse: 441142.4688\n",
            "Epoch 49/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 119.3896 - mae: 119.3896 - mse: 494461.8438 - val_loss: 122.2152 - val_mae: 122.2152 - val_mse: 440678.5312\n",
            "Epoch 50/50\n",
            "220/220 [==============================] - 1s 3ms/step - loss: 115.5536 - mae: 115.5536 - mse: 428809.6875 - val_loss: 122.1674 - val_mae: 122.1674 - val_mse: 439138.5938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model2.predict(enc_X_train)\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "r2_square = r2_score(y_train, y_pred)\n",
        "print('\\nMAE:', mae)\n",
        "print('\\nMSE:', mse)\n",
        "print('\\nRMSE:', rmse)\n",
        "print('\\nR2 Square', r2_square)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WehfYR83ROYD",
        "outputId": "e8e9e769-2f69-4f2d-c048-548564730101"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1764/1764 [==============================] - 2s 1ms/step\n",
            "\n",
            "MAE: 117.4770989439889\n",
            "\n",
            "MSE: 454769.5019682801\n",
            "\n",
            "RMSE: 674.3660000091049\n",
            "\n",
            "R2 Square 0.18037412754517101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 512 Nodes"
      ],
      "metadata": {
        "id": "LCTsTF4RR4lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Sequential([\n",
        "    Input(shape=(enc_X_train.shape[1],)),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model3.compile(optimizer='adam', \n",
        "              loss='mae',\n",
        "              metrics=['mae', 'mse'])"
      ],
      "metadata": {
        "id": "SsIJ_7sORjLx"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9nTky93RqXk",
        "outputId": "ca79f6bf-0720-4e53-cabb-daf3d3770edd"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 512)               27136     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,649\n",
            "Trainable params: 27,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(\n",
        "  enc_X_train, y_train,\n",
        "  validation_data=(enc_X_val, y_val),\n",
        "  steps_per_epoch = STEPS,\n",
        "  batch_size = BATCH_SIZE,\n",
        "  epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8ymQ8NeRvh9",
        "outputId": "9b2a0257-36bf-4f76-888f-272f84878bf1"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "220/220 [==============================] - 2s 6ms/step - loss: 189.9448 - mae: 189.9448 - mse: 570339.1875 - val_loss: 154.3378 - val_mae: 154.3378 - val_mse: 528313.9375\n",
            "Epoch 2/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 142.7716 - mae: 142.7716 - mse: 520436.8750 - val_loss: 142.5204 - val_mae: 142.5204 - val_mse: 503601.9062\n",
            "Epoch 3/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 136.4490 - mae: 136.4490 - mse: 502833.7500 - val_loss: 139.1053 - val_mae: 139.1053 - val_mse: 495728.3438\n",
            "Epoch 4/50\n",
            "220/220 [==============================] - 1s 4ms/step - loss: 134.3030 - mae: 134.3030 - mse: 502205.0625 - val_loss: 136.8414 - val_mae: 136.8414 - val_mse: 489579.6875\n",
            "Epoch 5/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 132.2545 - mae: 132.2545 - mse: 498491.4375 - val_loss: 135.1517 - val_mae: 135.1517 - val_mse: 483798.0625\n",
            "Epoch 6/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 130.4524 - mae: 130.4524 - mse: 492490.0938 - val_loss: 133.9182 - val_mae: 133.9182 - val_mse: 478532.3125\n",
            "Epoch 7/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 127.1091 - mae: 127.1091 - mse: 450001.7812 - val_loss: 132.5186 - val_mae: 132.5186 - val_mse: 476800.6875\n",
            "Epoch 8/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 129.1078 - mae: 129.1078 - mse: 510056.4062 - val_loss: 131.6582 - val_mae: 131.6582 - val_mse: 474359.0312\n",
            "Epoch 9/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 125.5594 - mae: 125.5594 - mse: 469430.5312 - val_loss: 130.6832 - val_mae: 130.6832 - val_mse: 471970.6250\n",
            "Epoch 10/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 127.6518 - mae: 127.6518 - mse: 492592.3438 - val_loss: 129.8439 - val_mae: 129.8439 - val_mse: 467910.3750\n",
            "Epoch 11/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 124.4107 - mae: 124.4107 - mse: 472680.3750 - val_loss: 129.0655 - val_mae: 129.0655 - val_mse: 465766.1562\n",
            "Epoch 12/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 125.3183 - mae: 125.3183 - mse: 477238.0000 - val_loss: 128.4798 - val_mae: 128.4798 - val_mse: 464010.3750\n",
            "Epoch 13/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 123.6693 - mae: 123.6693 - mse: 479189.0000 - val_loss: 127.9622 - val_mae: 127.9622 - val_mse: 462095.0938\n",
            "Epoch 14/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 122.8223 - mae: 122.8223 - mse: 464040.0000 - val_loss: 127.4765 - val_mae: 127.4765 - val_mse: 459814.1250\n",
            "Epoch 15/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 122.7470 - mae: 122.7470 - mse: 465348.2812 - val_loss: 126.9916 - val_mae: 126.9916 - val_mse: 459909.7188\n",
            "Epoch 16/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 123.3691 - mae: 123.3691 - mse: 485311.5938 - val_loss: 126.4668 - val_mae: 126.4668 - val_mse: 457565.1250\n",
            "Epoch 17/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 121.0659 - mae: 121.0659 - mse: 432894.5625 - val_loss: 126.0636 - val_mae: 126.0636 - val_mse: 455197.0625\n",
            "Epoch 18/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 120.9335 - mae: 120.9335 - mse: 463354.0000 - val_loss: 125.7371 - val_mae: 125.7371 - val_mse: 452564.2188\n",
            "Epoch 19/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 122.0173 - mae: 122.0173 - mse: 492260.3750 - val_loss: 125.2957 - val_mae: 125.2957 - val_mse: 452497.3125\n",
            "Epoch 20/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 120.8162 - mae: 120.8162 - mse: 450679.1250 - val_loss: 125.0443 - val_mae: 125.0443 - val_mse: 452365.8125\n",
            "Epoch 21/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 119.9744 - mae: 119.9744 - mse: 473802.5000 - val_loss: 124.6771 - val_mae: 124.6771 - val_mse: 450049.8125\n",
            "Epoch 22/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 120.1680 - mae: 120.1680 - mse: 465930.8750 - val_loss: 124.4583 - val_mae: 124.4583 - val_mse: 449858.8438\n",
            "Epoch 23/50\n",
            "220/220 [==============================] - 1s 7ms/step - loss: 121.3660 - mae: 121.3660 - mse: 465953.2812 - val_loss: 124.1686 - val_mae: 124.1686 - val_mse: 447587.8438\n",
            "Epoch 24/50\n",
            "220/220 [==============================] - 1s 7ms/step - loss: 117.1645 - mae: 117.1645 - mse: 420257.8750 - val_loss: 123.9347 - val_mae: 123.9347 - val_mse: 447113.1875\n",
            "Epoch 25/50\n",
            "220/220 [==============================] - 2s 7ms/step - loss: 122.2370 - mae: 122.2370 - mse: 511735.9688 - val_loss: 123.6617 - val_mae: 123.6617 - val_mse: 446503.6250\n",
            "Epoch 26/50\n",
            "220/220 [==============================] - 2s 11ms/step - loss: 118.8803 - mae: 118.8803 - mse: 458609.7500 - val_loss: 123.3891 - val_mae: 123.3891 - val_mse: 444510.9375\n",
            "Epoch 27/50\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 118.3400 - mae: 118.3400 - mse: 444543.0938 - val_loss: 123.3100 - val_mae: 123.3100 - val_mse: 444498.2500\n",
            "Epoch 28/50\n",
            "220/220 [==============================] - 2s 9ms/step - loss: 117.5437 - mae: 117.5437 - mse: 437275.5625 - val_loss: 123.0440 - val_mae: 123.0440 - val_mse: 443223.0000\n",
            "Epoch 29/50\n",
            "220/220 [==============================] - 3s 12ms/step - loss: 118.3116 - mae: 118.3116 - mse: 464762.2188 - val_loss: 122.8616 - val_mae: 122.8616 - val_mse: 442769.9062\n",
            "Epoch 30/50\n",
            "220/220 [==============================] - 3s 13ms/step - loss: 119.2337 - mae: 119.2337 - mse: 475461.0312 - val_loss: 122.9824 - val_mae: 122.9824 - val_mse: 440286.8750\n",
            "Epoch 31/50\n",
            "220/220 [==============================] - 2s 9ms/step - loss: 119.2489 - mae: 119.2489 - mse: 470506.8125 - val_loss: 122.5523 - val_mae: 122.5523 - val_mse: 441856.3750\n",
            "Epoch 32/50\n",
            "220/220 [==============================] - 1s 6ms/step - loss: 116.2006 - mae: 116.2006 - mse: 452800.0625 - val_loss: 122.3655 - val_mae: 122.3655 - val_mse: 440018.5000\n",
            "Epoch 33/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 118.8212 - mae: 118.8212 - mse: 444510.8125 - val_loss: 122.3510 - val_mae: 122.3510 - val_mse: 439414.6562\n",
            "Epoch 34/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 116.4645 - mae: 116.4645 - mse: 446874.6875 - val_loss: 122.1944 - val_mae: 122.1944 - val_mse: 441454.9062\n",
            "Epoch 35/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 118.3888 - mae: 118.3888 - mse: 477835.2188 - val_loss: 122.1174 - val_mae: 122.1174 - val_mse: 440661.3750\n",
            "Epoch 36/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 116.2817 - mae: 116.2817 - mse: 424968.4062 - val_loss: 121.9417 - val_mae: 121.9417 - val_mse: 438301.7812\n",
            "Epoch 37/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 119.5985 - mae: 119.5985 - mse: 498015.6875 - val_loss: 121.7686 - val_mae: 121.7686 - val_mse: 439065.3125\n",
            "Epoch 38/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 116.3857 - mae: 116.3857 - mse: 460757.3750 - val_loss: 121.7878 - val_mae: 121.7878 - val_mse: 439441.0625\n",
            "Epoch 39/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 116.4276 - mae: 116.4276 - mse: 425570.4688 - val_loss: 121.5266 - val_mae: 121.5266 - val_mse: 437889.8438\n",
            "Epoch 40/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 114.5591 - mae: 114.5591 - mse: 415756.2812 - val_loss: 121.3163 - val_mae: 121.3163 - val_mse: 436623.6875\n",
            "Epoch 41/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 118.4267 - mae: 118.4267 - mse: 501503.4062 - val_loss: 121.3254 - val_mae: 121.3254 - val_mse: 436417.5938\n",
            "Epoch 42/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 116.8045 - mae: 116.8045 - mse: 448898.3438 - val_loss: 121.2145 - val_mae: 121.2145 - val_mse: 436684.4688\n",
            "Epoch 43/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 115.5644 - mae: 115.5644 - mse: 435939.5312 - val_loss: 121.0677 - val_mae: 121.0677 - val_mse: 436580.6250\n",
            "Epoch 44/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 115.3018 - mae: 115.3018 - mse: 448022.3750 - val_loss: 120.9362 - val_mae: 120.9362 - val_mse: 436405.0312\n",
            "Epoch 45/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 117.7975 - mae: 117.7975 - mse: 463697.4062 - val_loss: 120.8339 - val_mae: 120.8339 - val_mse: 434654.7188\n",
            "Epoch 46/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 115.9927 - mae: 115.9927 - mse: 470842.9062 - val_loss: 120.8021 - val_mae: 120.8021 - val_mse: 436164.0312\n",
            "Epoch 47/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 115.1895 - mae: 115.1895 - mse: 426538.8438 - val_loss: 120.6114 - val_mae: 120.6114 - val_mse: 434602.3438\n",
            "Epoch 48/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 114.7191 - mae: 114.7191 - mse: 457436.9062 - val_loss: 120.8925 - val_mae: 120.8925 - val_mse: 432123.6875\n",
            "Epoch 49/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 115.9131 - mae: 115.9131 - mse: 458096.6562 - val_loss: 120.5588 - val_mae: 120.5588 - val_mse: 431860.9688\n",
            "Epoch 50/50\n",
            "220/220 [==============================] - 1s 5ms/step - loss: 115.4649 - mae: 115.4649 - mse: 438254.6562 - val_loss: 120.4145 - val_mae: 120.4145 - val_mse: 433733.6875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model3.predict(enc_X_val)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "r2_square = r2_score(y_val, y_pred)\n",
        "print('\\nMAE:', mae)\n",
        "print('\\nMSE:', mse)\n",
        "print('\\nRMSE:', rmse)\n",
        "print('\\nR2 Square', r2_square)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNBByV0ZR9oM",
        "outputId": "2f96dec6-aed2-4177-c1a6-7f763b290ca2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "378/378 [==============================] - 1s 1ms/step\n",
            "\n",
            "MAE: 120.41449211505119\n",
            "\n",
            "MSE: 433733.7233754506\n",
            "\n",
            "RMSE: 658.5846364556727\n",
            "\n",
            "R2 Square 0.21024304449248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Number of Layers"
      ],
      "metadata": {
        "id": "KIGUsjXDTho4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = Sequential([\n",
        "    Input(shape=(enc_X_train.shape[1],)),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model4.compile(optimizer='adam', \n",
        "              loss='mae',\n",
        "              metrics=['mae', 'mse'])"
      ],
      "metadata": {
        "id": "Jz5TD-OmTy2K"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngE1BFZCT6ZS",
        "outputId": "8a03ed4a-6440-4860-f4c2-310d151fbf24"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 512)               27136     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 512)              2048      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 823,809\n",
            "Trainable params: 819,713\n",
            "Non-trainable params: 4,096\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model4.fit(\n",
        "  enc_X_train, y_train,\n",
        "  validation_data=(enc_X_val, y_val),\n",
        "  steps_per_epoch = STEPS,\n",
        "  batch_size = BATCH_SIZE,\n",
        "  epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2BpWwTkUBPr",
        "outputId": "5510fa39-f69d-4d2d-f692-b3fd112f1f51"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "220/220 [==============================] - 13s 52ms/step - loss: 267.2754 - mae: 267.2754 - mse: 625171.6250 - val_loss: 191.5744 - val_mae: 191.5744 - val_mse: 564819.1875\n",
            "Epoch 2/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 169.9291 - mae: 169.9291 - mse: 544136.0000 - val_loss: 150.8344 - val_mae: 150.8344 - val_mse: 456132.4062\n",
            "Epoch 3/50\n",
            "220/220 [==============================] - 11s 50ms/step - loss: 124.9971 - mae: 124.9971 - mse: 476590.2500 - val_loss: 149.4885 - val_mae: 149.4885 - val_mse: 451440.0625\n",
            "Epoch 4/50\n",
            "220/220 [==============================] - 11s 50ms/step - loss: 123.0901 - mae: 123.0901 - mse: 476465.5000 - val_loss: 125.7916 - val_mae: 125.7916 - val_mse: 446139.8125\n",
            "Epoch 5/50\n",
            "220/220 [==============================] - 11s 50ms/step - loss: 121.4573 - mae: 121.4573 - mse: 466767.9062 - val_loss: 145.1029 - val_mae: 145.1029 - val_mse: 460663.9062\n",
            "Epoch 6/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 119.7900 - mae: 119.7900 - mse: 459681.4062 - val_loss: 123.6971 - val_mae: 123.6971 - val_mse: 446373.1250\n",
            "Epoch 7/50\n",
            "220/220 [==============================] - 12s 54ms/step - loss: 120.1883 - mae: 120.1883 - mse: 472719.0000 - val_loss: 124.6245 - val_mae: 124.6245 - val_mse: 448908.4062\n",
            "Epoch 8/50\n",
            "220/220 [==============================] - 13s 61ms/step - loss: 117.8816 - mae: 117.8816 - mse: 438198.2500 - val_loss: 121.5984 - val_mae: 121.5984 - val_mse: 433206.4062\n",
            "Epoch 9/50\n",
            "220/220 [==============================] - 13s 60ms/step - loss: 117.9620 - mae: 117.9620 - mse: 460337.4062 - val_loss: 119.7071 - val_mae: 119.7071 - val_mse: 424997.5938\n",
            "Epoch 10/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 117.9007 - mae: 117.9007 - mse: 479104.5000 - val_loss: 124.3008 - val_mae: 124.3008 - val_mse: 432106.8750\n",
            "Epoch 11/50\n",
            "220/220 [==============================] - 11s 50ms/step - loss: 116.9439 - mae: 116.9439 - mse: 462634.2500 - val_loss: 121.5903 - val_mae: 121.5903 - val_mse: 437113.7500\n",
            "Epoch 12/50\n",
            "220/220 [==============================] - 11s 50ms/step - loss: 115.7224 - mae: 115.7224 - mse: 436743.4062 - val_loss: 120.8661 - val_mae: 120.8661 - val_mse: 430908.8438\n",
            "Epoch 13/50\n",
            "220/220 [==============================] - 11s 50ms/step - loss: 115.9183 - mae: 115.9183 - mse: 462444.9375 - val_loss: 118.6097 - val_mae: 118.6097 - val_mse: 411935.9062\n",
            "Epoch 14/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 112.8633 - mae: 112.8633 - mse: 414991.6562 - val_loss: 120.5427 - val_mae: 120.5427 - val_mse: 423130.0000\n",
            "Epoch 15/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 114.8213 - mae: 114.8213 - mse: 451365.3750 - val_loss: 117.2927 - val_mae: 117.2927 - val_mse: 379088.3125\n",
            "Epoch 16/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 112.7105 - mae: 112.7105 - mse: 401997.9062 - val_loss: 118.5235 - val_mae: 118.5235 - val_mse: 390733.1875\n",
            "Epoch 17/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 114.3755 - mae: 114.3755 - mse: 433877.1250 - val_loss: 115.9146 - val_mae: 115.9146 - val_mse: 376503.7812\n",
            "Epoch 18/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 111.7623 - mae: 111.7623 - mse: 430521.0938 - val_loss: 121.2565 - val_mae: 121.2565 - val_mse: 367492.8438\n",
            "Epoch 19/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 109.3603 - mae: 109.3603 - mse: 372901.7188 - val_loss: 123.8604 - val_mae: 123.8604 - val_mse: 401233.2500\n",
            "Epoch 20/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 112.8299 - mae: 112.8299 - mse: 431869.4375 - val_loss: 118.2548 - val_mae: 118.2548 - val_mse: 365543.7812\n",
            "Epoch 21/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 110.4881 - mae: 110.4881 - mse: 400773.9375 - val_loss: 119.4090 - val_mae: 119.4090 - val_mse: 355231.3125\n",
            "Epoch 22/50\n",
            "220/220 [==============================] - 12s 52ms/step - loss: 109.0017 - mae: 109.0017 - mse: 365468.8750 - val_loss: 113.2373 - val_mae: 113.2373 - val_mse: 344263.9688\n",
            "Epoch 23/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 108.0555 - mae: 108.0555 - mse: 364365.5625 - val_loss: 115.1684 - val_mae: 115.1684 - val_mse: 323801.2188\n",
            "Epoch 24/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 111.8798 - mae: 111.8798 - mse: 435586.1875 - val_loss: 113.1911 - val_mae: 113.1911 - val_mse: 317911.5938\n",
            "Epoch 25/50\n",
            "220/220 [==============================] - 12s 54ms/step - loss: 105.4647 - mae: 105.4647 - mse: 315013.2500 - val_loss: 110.7705 - val_mae: 110.7705 - val_mse: 264536.4062\n",
            "Epoch 26/50\n",
            "220/220 [==============================] - 12s 53ms/step - loss: 106.9375 - mae: 106.9375 - mse: 389979.3750 - val_loss: 110.0322 - val_mae: 110.0322 - val_mse: 294975.4688\n",
            "Epoch 27/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 109.1758 - mae: 109.1758 - mse: 387562.7188 - val_loss: 110.8274 - val_mae: 110.8274 - val_mse: 303002.2812\n",
            "Epoch 28/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 103.3176 - mae: 103.3176 - mse: 305735.0938 - val_loss: 107.6968 - val_mae: 107.6968 - val_mse: 269773.5625\n",
            "Epoch 29/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 109.1940 - mae: 109.1940 - mse: 414921.2500 - val_loss: 110.7515 - val_mae: 110.7515 - val_mse: 293173.0938\n",
            "Epoch 30/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 103.3582 - mae: 103.3582 - mse: 311465.1875 - val_loss: 106.9035 - val_mae: 106.9035 - val_mse: 249963.1719\n",
            "Epoch 31/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 105.2754 - mae: 105.2754 - mse: 359383.1875 - val_loss: 110.1307 - val_mae: 110.1307 - val_mse: 221268.0625\n",
            "Epoch 32/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 106.6890 - mae: 106.6890 - mse: 381168.3125 - val_loss: 112.1804 - val_mae: 112.1804 - val_mse: 321675.6875\n",
            "Epoch 33/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 104.9581 - mae: 104.9581 - mse: 352108.1562 - val_loss: 107.3805 - val_mae: 107.3805 - val_mse: 258889.9844\n",
            "Epoch 34/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 103.5090 - mae: 103.5090 - mse: 338427.8750 - val_loss: 107.8317 - val_mae: 107.8317 - val_mse: 256594.9062\n",
            "Epoch 35/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 105.2963 - mae: 105.2963 - mse: 347850.0625 - val_loss: 108.5776 - val_mae: 108.5776 - val_mse: 236491.2812\n",
            "Epoch 36/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 102.1316 - mae: 102.1316 - mse: 306345.2188 - val_loss: 112.3587 - val_mae: 112.3587 - val_mse: 262144.8125\n",
            "Epoch 37/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 101.3514 - mae: 101.3514 - mse: 332672.9375 - val_loss: 109.8697 - val_mae: 109.8697 - val_mse: 270682.4688\n",
            "Epoch 38/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 102.5699 - mae: 102.5699 - mse: 319424.8750 - val_loss: 112.0197 - val_mae: 112.0197 - val_mse: 273789.8125\n",
            "Epoch 39/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 102.9294 - mae: 102.9294 - mse: 349632.2500 - val_loss: 107.9834 - val_mae: 107.9834 - val_mse: 264476.0938\n",
            "Epoch 40/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 100.1655 - mae: 100.1655 - mse: 304821.1562 - val_loss: 106.7539 - val_mae: 106.7539 - val_mse: 257806.2656\n",
            "Epoch 41/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 101.5585 - mae: 101.5585 - mse: 327278.6250 - val_loss: 111.7636 - val_mae: 111.7636 - val_mse: 280326.2188\n",
            "Epoch 42/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 100.2030 - mae: 100.2030 - mse: 309645.3125 - val_loss: 110.7992 - val_mae: 110.7992 - val_mse: 254144.0625\n",
            "Epoch 43/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 98.5054 - mae: 98.5054 - mse: 269644.5938 - val_loss: 105.9377 - val_mae: 105.9377 - val_mse: 211359.7031\n",
            "Epoch 44/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 97.1197 - mae: 97.1197 - mse: 285438.7500 - val_loss: 112.5807 - val_mae: 112.5807 - val_mse: 341073.6562\n",
            "Epoch 45/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 99.7667 - mae: 99.7667 - mse: 314901.5312 - val_loss: 112.1299 - val_mae: 112.1299 - val_mse: 269449.7812\n",
            "Epoch 46/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 98.3280 - mae: 98.3280 - mse: 292152.5000 - val_loss: 112.8963 - val_mae: 112.8963 - val_mse: 240333.8594\n",
            "Epoch 47/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 99.3544 - mae: 99.3544 - mse: 294090.6562 - val_loss: 111.2769 - val_mae: 111.2769 - val_mse: 301449.3750\n",
            "Epoch 48/50\n",
            "220/220 [==============================] - 11s 51ms/step - loss: 94.7459 - mae: 94.7459 - mse: 259573.5312 - val_loss: 120.9859 - val_mae: 120.9859 - val_mse: 433828.3125\n",
            "Epoch 49/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 95.2976 - mae: 95.2976 - mse: 287396.4688 - val_loss: 107.0710 - val_mae: 107.0710 - val_mse: 208748.4219\n",
            "Epoch 50/50\n",
            "220/220 [==============================] - 11s 52ms/step - loss: 95.3963 - mae: 95.3963 - mse: 282665.5625 - val_loss: 114.1488 - val_mae: 114.1488 - val_mse: 327523.0312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model4.predict(enc_X_val)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "mse = mean_squared_error(y_val, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "r2_square = r2_score(y_val, y_pred)\n",
        "print('\\nMAE:', mae)\n",
        "print('\\nMSE:', mse)\n",
        "print('\\nRMSE:', rmse)\n",
        "print('\\nR2 Square', r2_square)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0rXtCYkUXFE",
        "outputId": "25ff3c1b-ae2e-4e9d-b76e-f7acc87c6d89"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "378/378 [==============================] - 2s 5ms/step\n",
            "\n",
            "MAE: 114.14885271704173\n",
            "\n",
            "MSE: 327523.00311460893\n",
            "\n",
            "RMSE: 572.29625467463\n",
            "\n",
            "R2 Square 0.4036350971617487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archive"
      ],
      "metadata": {
        "id": "8M5nsylKUcZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in columns_to_category:\n",
        "  X_train[column] = X_train[column].astype('category')\n",
        "  X_test[column] = X_test[column].astype('category')"
      ],
      "metadata": {
        "id": "pRCi7k8aB2Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_X_train = X_train.copy()\n",
        "enc_X_test = X_test.copy()\n",
        "for column in categorical_columns:\n",
        "  enc_X_train[column] = enc_X_train[column].cat.codes\n",
        "  enc_X_test[column] = enc_X_test[column].cat.codes"
      ],
      "metadata": {
        "id": "7P5COCWCY_bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "for column in numeric_columns:\n",
        "  scaler = StandardScaler()\n",
        "  enc_X_train[column] = scaler.fit_transform(enc_X_train[[column]])\n",
        "  enc_X_test[column] = scaler.transform(enc_X_test[[column]])"
      ],
      "metadata": {
        "id": "r40M47ZIcYQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "8-LHUThDcTTy",
        "outputId": "765e6d59-6d03-482c-f655-9042b1367092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   description_sentiment  neighborhood_overview_sentiment  host_response_time  \\\n",
              "0                      2                                0                   4   \n",
              "1                      5                                0                   4   \n",
              "2                      5                                0                   4   \n",
              "3                      5                                0                   4   \n",
              "4                      2                                0                   4   \n",
              "\n",
              "   host_is_superhost  host_total_listings_count  host_has_profile_pic  \\\n",
              "0                  0                  -0.199155                     1   \n",
              "1                  0                  -0.204020                     1   \n",
              "2                  0                  -0.204020                     1   \n",
              "3                  1                  -0.192669                     1   \n",
              "4                  1                  -0.194290                     1   \n",
              "\n",
              "   host_identity_verified  latitude  longitude  property_type  room_type  \\\n",
              "0                       1 -1.230307   1.124547             19          0   \n",
              "1                       0 -0.306263   0.122492             19          0   \n",
              "2                       1 -1.043569   0.970018             15          0   \n",
              "3                       1 -0.363890   0.227839             17          0   \n",
              "4                       1 -0.548818   0.538765             53          2   \n",
              "\n",
              "   accommodates  bedrooms      beds  essentials    luxury  appliances  \\\n",
              "0     -0.030868  0.192831 -0.161844    0.010727 -0.783664   -0.440834   \n",
              "1     -0.030868  0.192831 -0.718963   -1.523132 -0.069257   -1.209680   \n",
              "2     -0.030868  0.192831 -0.161844   -0.500559  0.645151   -0.056411   \n",
              "3     -0.726006 -0.671228 -0.718963   -0.500559 -0.069257    0.328012   \n",
              "4     -1.073575 -0.671228 -0.718963    1.544587 -0.783664   -0.056411   \n",
              "\n",
              "   entertainment  security   comfort  furniture  miscellaneous  \\\n",
              "0      -0.385913 -1.569216 -0.800473   0.994949       0.140698   \n",
              "1      -0.385913 -0.408914 -0.800473  -0.760963      -0.661392   \n",
              "2      -0.385913 -0.408914 -0.800473   0.116993      -0.661392   \n",
              "3      -0.385913 -0.408914  0.775720  -0.760963      -0.317639   \n",
              "4      -0.385913 -1.569216 -0.800473   0.994949       0.599035   \n",
              "\n",
              "   availability_30  number_of_reviews  review_scores_rating  instant_bookable  \\\n",
              "0         0.944069          -0.027127                    27                 1   \n",
              "1         1.032936          -0.525110                    33                 0   \n",
              "2        -0.477810          -0.226320                    29                 0   \n",
              "3        -1.011014          -0.375715                    32                 1   \n",
              "4        -0.566677          -0.525110                    33                 0   \n",
              "\n",
              "   bathroom_qty  bathroom_type  \n",
              "0             1              1  \n",
              "1             1              1  \n",
              "2             1              1  \n",
              "3             1              1  \n",
              "4             1              4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c912a669-c3af-4ac9-863d-fbc51c345d87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description_sentiment</th>\n",
              "      <th>neighborhood_overview_sentiment</th>\n",
              "      <th>host_response_time</th>\n",
              "      <th>host_is_superhost</th>\n",
              "      <th>host_total_listings_count</th>\n",
              "      <th>host_has_profile_pic</th>\n",
              "      <th>host_identity_verified</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>property_type</th>\n",
              "      <th>room_type</th>\n",
              "      <th>accommodates</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>beds</th>\n",
              "      <th>essentials</th>\n",
              "      <th>luxury</th>\n",
              "      <th>appliances</th>\n",
              "      <th>entertainment</th>\n",
              "      <th>security</th>\n",
              "      <th>comfort</th>\n",
              "      <th>furniture</th>\n",
              "      <th>miscellaneous</th>\n",
              "      <th>availability_30</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>review_scores_rating</th>\n",
              "      <th>instant_bookable</th>\n",
              "      <th>bathroom_qty</th>\n",
              "      <th>bathroom_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.199155</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.230307</td>\n",
              "      <td>1.124547</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.030868</td>\n",
              "      <td>0.192831</td>\n",
              "      <td>-0.161844</td>\n",
              "      <td>0.010727</td>\n",
              "      <td>-0.783664</td>\n",
              "      <td>-0.440834</td>\n",
              "      <td>-0.385913</td>\n",
              "      <td>-1.569216</td>\n",
              "      <td>-0.800473</td>\n",
              "      <td>0.994949</td>\n",
              "      <td>0.140698</td>\n",
              "      <td>0.944069</td>\n",
              "      <td>-0.027127</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.204020</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.306263</td>\n",
              "      <td>0.122492</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.030868</td>\n",
              "      <td>0.192831</td>\n",
              "      <td>-0.718963</td>\n",
              "      <td>-1.523132</td>\n",
              "      <td>-0.069257</td>\n",
              "      <td>-1.209680</td>\n",
              "      <td>-0.385913</td>\n",
              "      <td>-0.408914</td>\n",
              "      <td>-0.800473</td>\n",
              "      <td>-0.760963</td>\n",
              "      <td>-0.661392</td>\n",
              "      <td>1.032936</td>\n",
              "      <td>-0.525110</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.204020</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.043569</td>\n",
              "      <td>0.970018</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.030868</td>\n",
              "      <td>0.192831</td>\n",
              "      <td>-0.161844</td>\n",
              "      <td>-0.500559</td>\n",
              "      <td>0.645151</td>\n",
              "      <td>-0.056411</td>\n",
              "      <td>-0.385913</td>\n",
              "      <td>-0.408914</td>\n",
              "      <td>-0.800473</td>\n",
              "      <td>0.116993</td>\n",
              "      <td>-0.661392</td>\n",
              "      <td>-0.477810</td>\n",
              "      <td>-0.226320</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.192669</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.363890</td>\n",
              "      <td>0.227839</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.726006</td>\n",
              "      <td>-0.671228</td>\n",
              "      <td>-0.718963</td>\n",
              "      <td>-0.500559</td>\n",
              "      <td>-0.069257</td>\n",
              "      <td>0.328012</td>\n",
              "      <td>-0.385913</td>\n",
              "      <td>-0.408914</td>\n",
              "      <td>0.775720</td>\n",
              "      <td>-0.760963</td>\n",
              "      <td>-0.317639</td>\n",
              "      <td>-1.011014</td>\n",
              "      <td>-0.375715</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.194290</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.548818</td>\n",
              "      <td>0.538765</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.073575</td>\n",
              "      <td>-0.671228</td>\n",
              "      <td>-0.718963</td>\n",
              "      <td>1.544587</td>\n",
              "      <td>-0.783664</td>\n",
              "      <td>-0.056411</td>\n",
              "      <td>-0.385913</td>\n",
              "      <td>-1.569216</td>\n",
              "      <td>-0.800473</td>\n",
              "      <td>0.994949</td>\n",
              "      <td>0.599035</td>\n",
              "      <td>-0.566677</td>\n",
              "      <td>-0.525110</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c912a669-c3af-4ac9-863d-fbc51c345d87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c912a669-c3af-4ac9-863d-fbc51c345d87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c912a669-c3af-4ac9-863d-fbc51c345d87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoSxHJMEdpN7",
        "outputId": "9e100abc-053a-413d-c560-f4ddd9d4bb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64440, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "enc_X_val, enc_X_test, enc_y_val, enc_y_test = train_test_split(enc_X_test, y_test, test_size=0.5)"
      ],
      "metadata": {
        "id": "JpwKqSnIeFB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization\n",
        "\n",
        "model1 = Sequential([\n",
        "    Input(shape=(enc_X_train.shape[1],)),\n",
        "    Dense(15, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model1.compile(optimizer='adam', \n",
        "              loss='mae',\n",
        "              metrics=['mae', 'mse'])"
      ],
      "metadata": {
        "id": "Smd8slI1c6JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb0IaMcBfWmi",
        "outputId": "d5116be3-dcfe-4781-98c4-724d7e123f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 15)                435       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 451\n",
            "Trainable params: 451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "STEPS = X_train.shape[0] // BATCH_SIZE\n",
        "\n",
        "history = model1.fit(\n",
        "  enc_X_train, y_train,\n",
        "  validation_data=(enc_X_val, enc_y_val),\n",
        "  steps_per_epoch = STEPS,\n",
        "  batch_size = BATCH_SIZE,\n",
        "  epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qlzs157YfZhe",
        "outputId": "c9118066-3fd6-4e8b-dce7-bb3a77f4abe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 123.2180 - mae: 123.2180 - mse: 244740.7344 - val_loss: 133.4990 - val_mae: 133.4990 - val_mse: 262657.5312\n",
            "Epoch 2/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 123.2414 - mae: 123.2414 - mse: 244703.8438 - val_loss: 132.4001 - val_mae: 132.4001 - val_mse: 262368.8125\n",
            "Epoch 3/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.8867 - mae: 122.8867 - mse: 241688.1875 - val_loss: 133.0447 - val_mae: 133.0447 - val_mse: 262538.2188\n",
            "Epoch 4/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 123.0607 - mae: 123.0607 - mse: 245396.1250 - val_loss: 132.0369 - val_mae: 132.0369 - val_mse: 261439.9844\n",
            "Epoch 5/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.8098 - mae: 122.8098 - mse: 242303.9531 - val_loss: 133.5776 - val_mae: 133.5776 - val_mse: 262448.8438\n",
            "Epoch 6/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.9211 - mae: 122.9211 - mse: 245244.8281 - val_loss: 133.1036 - val_mae: 133.1036 - val_mse: 262315.3125\n",
            "Epoch 7/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.3006 - mae: 122.3006 - mse: 239294.4062 - val_loss: 130.8376 - val_mae: 130.8376 - val_mse: 260979.7969\n",
            "Epoch 8/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.8144 - mae: 122.8144 - mse: 243871.5781 - val_loss: 132.5479 - val_mae: 132.5479 - val_mse: 262274.6562\n",
            "Epoch 9/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.1861 - mae: 122.1861 - mse: 242358.7812 - val_loss: 132.3424 - val_mae: 132.3424 - val_mse: 261774.7031\n",
            "Epoch 10/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 123.0537 - mae: 123.0537 - mse: 247844.1875 - val_loss: 131.9321 - val_mae: 131.9321 - val_mse: 261669.4688\n",
            "Epoch 11/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.5698 - mae: 122.5698 - mse: 240896.7656 - val_loss: 131.9733 - val_mae: 131.9733 - val_mse: 261937.5312\n",
            "Epoch 12/50\n",
            "251/251 [==============================] - 1s 2ms/step - loss: 121.8864 - mae: 121.8864 - mse: 238608.7812 - val_loss: 132.5063 - val_mae: 132.5063 - val_mse: 261638.1094\n",
            "Epoch 13/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.4053 - mae: 122.4053 - mse: 243781.4375 - val_loss: 133.0377 - val_mae: 133.0377 - val_mse: 262387.6875\n",
            "Epoch 14/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.3705 - mae: 121.3705 - mse: 237366.3594 - val_loss: 131.2878 - val_mae: 131.2878 - val_mse: 261213.0312\n",
            "Epoch 15/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.8271 - mae: 122.8271 - mse: 248447.3125 - val_loss: 132.0337 - val_mae: 132.0337 - val_mse: 261672.7812\n",
            "Epoch 16/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.4076 - mae: 122.4076 - mse: 241167.3125 - val_loss: 132.8942 - val_mae: 132.8942 - val_mse: 262260.3125\n",
            "Epoch 17/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.3574 - mae: 121.3574 - mse: 237172.1719 - val_loss: 132.2365 - val_mae: 132.2365 - val_mse: 262013.4844\n",
            "Epoch 18/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.1168 - mae: 122.1168 - mse: 242876.5469 - val_loss: 132.4151 - val_mae: 132.4151 - val_mse: 261744.9531\n",
            "Epoch 19/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.5612 - mae: 122.5612 - mse: 245636.6719 - val_loss: 131.2445 - val_mae: 131.2445 - val_mse: 261023.8281\n",
            "Epoch 20/50\n",
            "251/251 [==============================] - 1s 2ms/step - loss: 121.3130 - mae: 121.3130 - mse: 243352.8906 - val_loss: 132.1615 - val_mae: 132.1615 - val_mse: 261587.8594\n",
            "Epoch 21/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.7929 - mae: 121.7929 - mse: 240728.1094 - val_loss: 131.6391 - val_mae: 131.6391 - val_mse: 261337.5469\n",
            "Epoch 22/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.8590 - mae: 120.8590 - mse: 235073.1875 - val_loss: 131.2939 - val_mae: 131.2939 - val_mse: 260934.6094\n",
            "Epoch 23/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.3272 - mae: 121.3272 - mse: 237364.6250 - val_loss: 131.0800 - val_mae: 131.0800 - val_mse: 260993.8281\n",
            "Epoch 24/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.0783 - mae: 122.0783 - mse: 243041.9688 - val_loss: 132.4174 - val_mae: 132.4174 - val_mse: 261333.8438\n",
            "Epoch 25/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.3313 - mae: 121.3313 - mse: 237807.0156 - val_loss: 131.6162 - val_mae: 131.6162 - val_mse: 261273.3594\n",
            "Epoch 26/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.5038 - mae: 121.5038 - mse: 242594.1562 - val_loss: 132.5004 - val_mae: 132.5004 - val_mse: 261912.1406\n",
            "Epoch 27/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.1615 - mae: 121.1615 - mse: 238037.3594 - val_loss: 132.4961 - val_mae: 132.4961 - val_mse: 261854.5781\n",
            "Epoch 28/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.2456 - mae: 122.2456 - mse: 244309.7188 - val_loss: 131.0334 - val_mae: 131.0334 - val_mse: 260183.8281\n",
            "Epoch 29/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.5453 - mae: 120.5453 - mse: 238443.9531 - val_loss: 131.6180 - val_mae: 131.6180 - val_mse: 261075.1250\n",
            "Epoch 30/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.4328 - mae: 121.4328 - mse: 241274.3594 - val_loss: 131.5077 - val_mae: 131.5077 - val_mse: 261252.7500\n",
            "Epoch 31/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.5522 - mae: 120.5522 - mse: 235011.8906 - val_loss: 131.1174 - val_mae: 131.1174 - val_mse: 260997.6250\n",
            "Epoch 32/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.2356 - mae: 122.2356 - mse: 247607.1094 - val_loss: 130.4155 - val_mae: 130.4155 - val_mse: 260465.4531\n",
            "Epoch 33/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 119.5607 - mae: 119.5607 - mse: 224678.0469 - val_loss: 131.5044 - val_mae: 131.5044 - val_mse: 261244.7188\n",
            "Epoch 34/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.7830 - mae: 121.7830 - mse: 251730.3594 - val_loss: 131.7687 - val_mae: 131.7687 - val_mse: 261889.7969\n",
            "Epoch 35/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.2402 - mae: 121.2402 - mse: 238673.5781 - val_loss: 130.8904 - val_mae: 130.8904 - val_mse: 260980.9844\n",
            "Epoch 36/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.2213 - mae: 120.2213 - mse: 231077.2188 - val_loss: 131.3527 - val_mae: 131.3527 - val_mse: 260894.7031\n",
            "Epoch 37/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.7076 - mae: 121.7076 - mse: 247640.9062 - val_loss: 130.9977 - val_mae: 130.9977 - val_mse: 260925.1094\n",
            "Epoch 38/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.6339 - mae: 120.6339 - mse: 233950.8281 - val_loss: 131.9735 - val_mae: 131.9735 - val_mse: 261321.1094\n",
            "Epoch 39/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.9270 - mae: 120.9270 - mse: 236028.5781 - val_loss: 130.7350 - val_mae: 130.7350 - val_mse: 260503.0781\n",
            "Epoch 40/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.2147 - mae: 122.2147 - mse: 252151.4219 - val_loss: 131.2268 - val_mae: 131.2268 - val_mse: 260789.6875\n",
            "Epoch 41/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 119.8304 - mae: 119.8304 - mse: 231194.6094 - val_loss: 131.5181 - val_mae: 131.5181 - val_mse: 261162.2969\n",
            "Epoch 42/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.1217 - mae: 120.1217 - mse: 237927.6875 - val_loss: 132.1983 - val_mae: 132.1983 - val_mse: 262064.7031\n",
            "Epoch 43/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.3353 - mae: 120.3353 - mse: 231082.4844 - val_loss: 130.5606 - val_mae: 130.5606 - val_mse: 260536.1094\n",
            "Epoch 44/50\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.4412 - mae: 122.4412 - mse: 253496.9062 - val_loss: 130.3180 - val_mae: 130.3180 - val_mse: 260442.2500\n",
            "Epoch 45/50\n",
            "251/251 [==============================] - 1s 4ms/step - loss: 120.3062 - mae: 120.3062 - mse: 237652.8594 - val_loss: 131.4982 - val_mae: 131.4982 - val_mse: 261201.8438\n",
            "Epoch 46/50\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.0955 - mae: 120.0955 - mse: 233147.4062 - val_loss: 130.9591 - val_mae: 130.9591 - val_mse: 260770.9688\n",
            "Epoch 47/50\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.3336 - mae: 121.3336 - mse: 245889.2812 - val_loss: 130.4592 - val_mae: 130.4592 - val_mse: 260591.6250\n",
            "Epoch 48/50\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 119.6943 - mae: 119.6943 - mse: 232580.4375 - val_loss: 132.5047 - val_mae: 132.5047 - val_mse: 261632.3906\n",
            "Epoch 49/50\n",
            "251/251 [==============================] - 1s 4ms/step - loss: 120.2215 - mae: 120.2215 - mse: 236399.0781 - val_loss: 131.3025 - val_mae: 131.3025 - val_mse: 260547.7969\n",
            "Epoch 50/50\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.3771 - mae: 122.3771 - mse: 249490.6250 - val_loss: 130.3325 - val_mae: 130.3325 - val_mse: 260205.1875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.evaluate(enc_X_test, enc_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXjsbr1Df1WS",
        "outputId": "354a71ac-1d31-4d2f-f4c6-d837babc8456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252/252 [==============================] - 1s 2ms/step - loss: 143.0486 - mae: 143.0486 - mse: 346189.3125\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[143.04856872558594, 143.04856872558594, 346189.3125]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "    Input(shape=(enc_X_train.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model2.compile(optimizer='adam', \n",
        "              loss='mae',\n",
        "              metrics=['mae', 'mse'])\n",
        "\n",
        "history = model2.fit(\n",
        "  enc_X_train, y_train,\n",
        "  validation_data=(enc_X_val, enc_y_val),\n",
        "  steps_per_epoch = STEPS,\n",
        "  batch_size = BATCH_SIZE,\n",
        "  epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuHt1epYhw3m",
        "outputId": "b7a93b65-0e72-4da1-e236-791c2b24d174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 189.9617 - mae: 189.9617 - mse: 316448.2500 - val_loss: 152.9634 - val_mae: 152.9634 - val_mse: 290668.9375\n",
            "Epoch 2/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 138.4154 - mae: 138.4154 - mse: 271853.4375 - val_loss: 140.0358 - val_mae: 140.0358 - val_mse: 277365.6875\n",
            "Epoch 3/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 133.5099 - mae: 133.5099 - mse: 261643.9844 - val_loss: 137.4888 - val_mae: 137.4888 - val_mse: 272997.7812\n",
            "Epoch 4/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 131.6907 - mae: 131.6907 - mse: 266827.2500 - val_loss: 137.1376 - val_mae: 137.1376 - val_mse: 270821.0312\n",
            "Epoch 5/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 129.7571 - mae: 129.7571 - mse: 260051.5156 - val_loss: 134.1320 - val_mae: 134.1320 - val_mse: 267158.7812\n",
            "Epoch 6/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 128.9939 - mae: 128.9939 - mse: 255982.2969 - val_loss: 132.4801 - val_mae: 132.4801 - val_mse: 265284.7812\n",
            "Epoch 7/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 127.0213 - mae: 127.0213 - mse: 250965.0625 - val_loss: 134.5590 - val_mae: 134.5590 - val_mse: 265721.3750\n",
            "Epoch 8/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 127.7863 - mae: 127.7863 - mse: 257055.2969 - val_loss: 133.1766 - val_mae: 133.1766 - val_mse: 264561.5000\n",
            "Epoch 9/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 126.9776 - mae: 126.9776 - mse: 256571.5938 - val_loss: 133.2576 - val_mae: 133.2576 - val_mse: 264861.0312\n",
            "Epoch 10/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 125.3606 - mae: 125.3606 - mse: 248001.3594 - val_loss: 133.4161 - val_mae: 133.4161 - val_mse: 264361.9375\n",
            "Epoch 11/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 125.3271 - mae: 125.3271 - mse: 250445.9688 - val_loss: 133.0041 - val_mae: 133.0041 - val_mse: 264045.3750\n",
            "Epoch 12/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 124.9231 - mae: 124.9231 - mse: 247875.4688 - val_loss: 135.1303 - val_mae: 135.1303 - val_mse: 264492.9062\n",
            "Epoch 13/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 124.4900 - mae: 124.4900 - mse: 251373.5781 - val_loss: 133.7687 - val_mae: 133.7687 - val_mse: 265131.0625\n",
            "Epoch 14/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 123.6756 - mae: 123.6756 - mse: 243978.6562 - val_loss: 133.5172 - val_mae: 133.5172 - val_mse: 263714.7188\n",
            "Epoch 15/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 123.6073 - mae: 123.6073 - mse: 246547.1719 - val_loss: 131.5928 - val_mae: 131.5928 - val_mse: 262794.7500\n",
            "Epoch 16/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 124.0733 - mae: 124.0733 - mse: 250525.1094 - val_loss: 132.9721 - val_mae: 132.9721 - val_mse: 263202.5938\n",
            "Epoch 17/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.1500 - mae: 122.1500 - mse: 240218.2031 - val_loss: 132.5134 - val_mae: 132.5134 - val_mse: 262474.9375\n",
            "Epoch 18/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 123.1534 - mae: 123.1534 - mse: 248454.8281 - val_loss: 133.4373 - val_mae: 133.4373 - val_mse: 263183.5000\n",
            "Epoch 19/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.5899 - mae: 122.5899 - mse: 245520.7500 - val_loss: 131.9041 - val_mae: 131.9041 - val_mse: 262262.4375\n",
            "Epoch 20/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.6743 - mae: 122.6743 - mse: 246914.5469 - val_loss: 131.8391 - val_mae: 131.8391 - val_mse: 262187.5000\n",
            "Epoch 21/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.5339 - mae: 121.5339 - mse: 240284.6562 - val_loss: 131.7786 - val_mae: 131.7786 - val_mse: 261642.7500\n",
            "Epoch 22/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.5065 - mae: 120.5065 - mse: 232892.3594 - val_loss: 131.3754 - val_mae: 131.3754 - val_mse: 261287.7500\n",
            "Epoch 23/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 122.1507 - mae: 122.1507 - mse: 247299.6562 - val_loss: 132.2318 - val_mae: 132.2318 - val_mse: 261806.2812\n",
            "Epoch 24/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.6385 - mae: 120.6385 - mse: 242061.7344 - val_loss: 132.1832 - val_mae: 132.1832 - val_mse: 262515.8125\n",
            "Epoch 25/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 121.4623 - mae: 121.4623 - mse: 241703.8438 - val_loss: 130.2024 - val_mae: 130.2024 - val_mse: 261126.5781\n",
            "Epoch 26/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.6958 - mae: 120.6958 - mse: 235916.8281 - val_loss: 132.9720 - val_mae: 132.9720 - val_mse: 262958.4688\n",
            "Epoch 27/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.5819 - mae: 120.5819 - mse: 241071.8125 - val_loss: 131.4173 - val_mae: 131.4173 - val_mse: 261517.4688\n",
            "Epoch 28/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.8975 - mae: 120.8975 - mse: 241660.5781 - val_loss: 132.5179 - val_mae: 132.5179 - val_mse: 262215.3125\n",
            "Epoch 29/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.1552 - mae: 120.1552 - mse: 239588.9844 - val_loss: 130.3523 - val_mae: 130.3523 - val_mse: 260824.6406\n",
            "Epoch 30/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.4769 - mae: 120.4769 - mse: 244147.0156 - val_loss: 130.7231 - val_mae: 130.7231 - val_mse: 260534.5938\n",
            "Epoch 31/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 119.2285 - mae: 119.2285 - mse: 232703.1875 - val_loss: 132.1300 - val_mae: 132.1300 - val_mse: 261332.2344\n",
            "Epoch 32/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 119.4738 - mae: 119.4738 - mse: 237474.0469 - val_loss: 132.0001 - val_mae: 132.0001 - val_mse: 260393.1406\n",
            "Epoch 33/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.7393 - mae: 120.7393 - mse: 244329.6406 - val_loss: 132.4942 - val_mae: 132.4942 - val_mse: 261410.8906\n",
            "Epoch 34/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 119.3201 - mae: 119.3201 - mse: 239212.7656 - val_loss: 131.4080 - val_mae: 131.4080 - val_mse: 260896.0312\n",
            "Epoch 35/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 118.6307 - mae: 118.6307 - mse: 227495.4688 - val_loss: 131.2080 - val_mae: 131.2080 - val_mse: 260068.3750\n",
            "Epoch 36/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.2300 - mae: 120.2300 - mse: 241741.3281 - val_loss: 131.3153 - val_mae: 131.3153 - val_mse: 260664.6875\n",
            "Epoch 37/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 118.9940 - mae: 118.9940 - mse: 236764.5625 - val_loss: 133.6992 - val_mae: 133.6992 - val_mse: 262171.8125\n",
            "Epoch 38/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 119.1223 - mae: 119.1223 - mse: 235165.3438 - val_loss: 129.7478 - val_mae: 129.7478 - val_mse: 259220.1875\n",
            "Epoch 39/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 120.0431 - mae: 120.0431 - mse: 248259.7188 - val_loss: 130.9972 - val_mae: 130.9972 - val_mse: 260093.3281\n",
            "Epoch 40/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 118.2349 - mae: 118.2349 - mse: 231312.7188 - val_loss: 131.1248 - val_mae: 131.1248 - val_mse: 259470.8594\n",
            "Epoch 41/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 116.9753 - mae: 116.9753 - mse: 226523.9219 - val_loss: 132.4858 - val_mae: 132.4858 - val_mse: 260822.3438\n",
            "Epoch 42/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 119.6206 - mae: 119.6206 - mse: 241676.0312 - val_loss: 129.7185 - val_mae: 129.7185 - val_mse: 259737.1250\n",
            "Epoch 43/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 119.0205 - mae: 119.0205 - mse: 241217.8750 - val_loss: 132.4775 - val_mae: 132.4775 - val_mse: 261325.8750\n",
            "Epoch 44/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 118.1820 - mae: 118.1820 - mse: 233910.8125 - val_loss: 132.7080 - val_mae: 132.7080 - val_mse: 260921.3125\n",
            "Epoch 45/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 118.2081 - mae: 118.2081 - mse: 233946.7344 - val_loss: 128.4101 - val_mae: 128.4101 - val_mse: 258044.7344\n",
            "Epoch 46/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 118.6946 - mae: 118.6946 - mse: 234322.5312 - val_loss: 130.5289 - val_mae: 130.5289 - val_mse: 259363.1250\n",
            "Epoch 47/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 117.7116 - mae: 117.7116 - mse: 235806.9531 - val_loss: 132.6826 - val_mae: 132.6826 - val_mse: 260598.2969\n",
            "Epoch 48/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 118.4798 - mae: 118.4798 - mse: 236929.3594 - val_loss: 131.7318 - val_mae: 131.7318 - val_mse: 259928.8281\n",
            "Epoch 49/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 118.0665 - mae: 118.0665 - mse: 236600.1406 - val_loss: 131.5333 - val_mae: 131.5333 - val_mse: 259189.4375\n",
            "Epoch 50/50\n",
            "251/251 [==============================] - 1s 3ms/step - loss: 117.7437 - mae: 117.7437 - mse: 235007.7031 - val_loss: 131.9431 - val_mae: 131.9431 - val_mse: 260551.8438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Sequential([\n",
        "    Input(shape=(enc_X_train.shape[1],)),\n",
        "    Dense(15, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(15, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(15, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(15, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.1),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model3.compile(optimizer='adam', \n",
        "              loss='mae',\n",
        "              metrics=['mae', 'mse'])\n",
        "\n",
        "EPOCHS=100\n",
        "\n",
        "history = model3.fit(\n",
        "  enc_X_train, y_train,\n",
        "  validation_data=(enc_X_val, enc_y_val),\n",
        "  steps_per_epoch = STEPS,\n",
        "  batch_size = BATCH_SIZE,\n",
        "  epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMIXOUlsiUK3",
        "outputId": "154a42cf-3d9c-4fcd-cb46-52483440423b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "251/251 [==============================] - 3s 6ms/step - loss: 271.9605 - mae: 271.9605 - mse: 370247.2500 - val_loss: 266.3028 - val_mae: 266.3028 - val_mse: 360607.5625\n",
            "Epoch 2/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 266.1590 - mae: 266.1590 - mse: 366353.0938 - val_loss: 258.2545 - val_mae: 258.2545 - val_mse: 356207.0312\n",
            "Epoch 3/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 255.8228 - mae: 255.8228 - mse: 358945.7812 - val_loss: 244.0436 - val_mae: 244.0436 - val_mse: 349133.5000\n",
            "Epoch 4/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 241.7765 - mae: 241.7765 - mse: 355147.1562 - val_loss: 225.2962 - val_mae: 225.2962 - val_mse: 338692.3125\n",
            "Epoch 5/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 223.1200 - mae: 223.1200 - mse: 341436.0625 - val_loss: 204.8574 - val_mae: 204.8574 - val_mse: 325628.3438\n",
            "Epoch 6/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 201.7503 - mae: 201.7503 - mse: 325217.2500 - val_loss: 193.9782 - val_mae: 193.9782 - val_mse: 316772.4062\n",
            "Epoch 7/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 179.6756 - mae: 179.6756 - mse: 311842.3750 - val_loss: 182.9811 - val_mae: 182.9811 - val_mse: 306601.9375\n",
            "Epoch 8/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 161.4827 - mae: 161.4827 - mse: 300282.4375 - val_loss: 157.9473 - val_mae: 157.9473 - val_mse: 291450.3750\n",
            "Epoch 9/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 145.5195 - mae: 145.5195 - mse: 278715.6562 - val_loss: 155.7291 - val_mae: 155.7291 - val_mse: 290921.4062\n",
            "Epoch 10/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 137.7222 - mae: 137.7222 - mse: 269073.2500 - val_loss: 146.8307 - val_mae: 146.8307 - val_mse: 284100.3125\n",
            "Epoch 11/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 133.0234 - mae: 133.0234 - mse: 264364.2500 - val_loss: 143.3211 - val_mae: 143.3211 - val_mse: 280804.6250\n",
            "Epoch 12/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 129.0635 - mae: 129.0635 - mse: 256887.7812 - val_loss: 140.8029 - val_mae: 140.8029 - val_mse: 277414.6250\n",
            "Epoch 13/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 128.0573 - mae: 128.0573 - mse: 256319.5938 - val_loss: 136.8216 - val_mae: 136.8216 - val_mse: 274456.9688\n",
            "Epoch 14/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 126.3635 - mae: 126.3635 - mse: 249459.0156 - val_loss: 137.5206 - val_mae: 137.5206 - val_mse: 275521.0000\n",
            "Epoch 15/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 124.9917 - mae: 124.9917 - mse: 237296.4844 - val_loss: 138.2665 - val_mae: 138.2665 - val_mse: 274537.8750\n",
            "Epoch 16/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 126.0500 - mae: 126.0500 - mse: 251812.2969 - val_loss: 133.9256 - val_mae: 133.9256 - val_mse: 269666.8438\n",
            "Epoch 17/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 124.9280 - mae: 124.9280 - mse: 236187.9219 - val_loss: 134.9057 - val_mae: 134.9057 - val_mse: 272460.8750\n",
            "Epoch 18/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 124.3371 - mae: 124.3371 - mse: 242431.6094 - val_loss: 133.8452 - val_mae: 133.8452 - val_mse: 271230.7188\n",
            "Epoch 19/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 125.0384 - mae: 125.0384 - mse: 238311.0781 - val_loss: 134.4296 - val_mae: 134.4296 - val_mse: 272406.2812\n",
            "Epoch 20/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 124.3242 - mae: 124.3242 - mse: 242851.7344 - val_loss: 136.6149 - val_mae: 136.6149 - val_mse: 274045.3438\n",
            "Epoch 21/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 125.0105 - mae: 125.0105 - mse: 239344.8594 - val_loss: 136.3539 - val_mae: 136.3539 - val_mse: 274234.0625\n",
            "Epoch 22/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 123.4999 - mae: 123.4999 - mse: 234208.0469 - val_loss: 133.7804 - val_mae: 133.7804 - val_mse: 271215.5000\n",
            "Epoch 23/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 123.5029 - mae: 123.5029 - mse: 232880.4219 - val_loss: 132.8144 - val_mae: 132.8144 - val_mse: 270714.0312\n",
            "Epoch 24/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 123.4819 - mae: 123.4819 - mse: 236590.5625 - val_loss: 132.9825 - val_mae: 132.9825 - val_mse: 270681.3125\n",
            "Epoch 25/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.7084 - mae: 122.7084 - mse: 229441.5781 - val_loss: 131.6091 - val_mae: 131.6091 - val_mse: 267114.2812\n",
            "Epoch 26/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 123.7179 - mae: 123.7179 - mse: 238033.2188 - val_loss: 134.9465 - val_mae: 134.9465 - val_mse: 272067.6562\n",
            "Epoch 27/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 123.2559 - mae: 123.2559 - mse: 239107.4531 - val_loss: 132.1807 - val_mae: 132.1807 - val_mse: 269710.5000\n",
            "Epoch 28/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 124.1493 - mae: 124.1493 - mse: 237160.7969 - val_loss: 136.6598 - val_mae: 136.6598 - val_mse: 273481.3438\n",
            "Epoch 29/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 123.3982 - mae: 123.3982 - mse: 234796.9062 - val_loss: 132.4557 - val_mae: 132.4557 - val_mse: 269212.3125\n",
            "Epoch 30/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 124.0702 - mae: 124.0702 - mse: 240552.0469 - val_loss: 131.2700 - val_mae: 131.2700 - val_mse: 268584.2500\n",
            "Epoch 31/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.8239 - mae: 121.8239 - mse: 227786.9688 - val_loss: 136.0945 - val_mae: 136.0945 - val_mse: 273920.6250\n",
            "Epoch 32/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.7538 - mae: 122.7538 - mse: 237581.0312 - val_loss: 127.5185 - val_mae: 127.5185 - val_mse: 263260.8750\n",
            "Epoch 33/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.6210 - mae: 122.6210 - mse: 228161.9844 - val_loss: 137.7393 - val_mae: 137.7393 - val_mse: 274657.9688\n",
            "Epoch 34/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 123.0193 - mae: 123.0193 - mse: 242943.2812 - val_loss: 133.2428 - val_mae: 133.2428 - val_mse: 270726.2812\n",
            "Epoch 35/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.0388 - mae: 121.0388 - mse: 223181.3750 - val_loss: 130.6954 - val_mae: 130.6954 - val_mse: 267751.3438\n",
            "Epoch 36/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.8683 - mae: 122.8683 - mse: 236857.9844 - val_loss: 135.6925 - val_mae: 135.6925 - val_mse: 272764.0312\n",
            "Epoch 37/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.0919 - mae: 122.0919 - mse: 232902.8906 - val_loss: 127.9817 - val_mae: 127.9817 - val_mse: 264582.0938\n",
            "Epoch 38/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.0976 - mae: 120.0976 - mse: 223226.7656 - val_loss: 128.2021 - val_mae: 128.2021 - val_mse: 265418.0938\n",
            "Epoch 39/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 123.8360 - mae: 123.8360 - mse: 247860.0781 - val_loss: 141.7483 - val_mae: 141.7483 - val_mse: 277371.7500\n",
            "Epoch 40/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.6851 - mae: 120.6851 - mse: 227510.8281 - val_loss: 136.3574 - val_mae: 136.3574 - val_mse: 270971.3125\n",
            "Epoch 41/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.0560 - mae: 120.0560 - mse: 228724.4062 - val_loss: 124.4124 - val_mae: 124.4124 - val_mse: 258614.8281\n",
            "Epoch 42/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.4696 - mae: 122.4696 - mse: 233035.7969 - val_loss: 125.6752 - val_mae: 125.6752 - val_mse: 260216.2656\n",
            "Epoch 43/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.6167 - mae: 120.6167 - mse: 226331.0000 - val_loss: 134.3281 - val_mae: 134.3281 - val_mse: 271819.5312\n",
            "Epoch 44/100\n",
            "251/251 [==============================] - 1s 4ms/step - loss: 121.8702 - mae: 121.8702 - mse: 235917.4844 - val_loss: 132.6879 - val_mae: 132.6879 - val_mse: 268658.4062\n",
            "Epoch 45/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.3885 - mae: 120.3885 - mse: 230170.6875 - val_loss: 147.4815 - val_mae: 147.4815 - val_mse: 283669.1562\n",
            "Epoch 46/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.5827 - mae: 120.5827 - mse: 220046.7188 - val_loss: 131.4969 - val_mae: 131.4969 - val_mse: 266089.2188\n",
            "Epoch 47/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.8919 - mae: 121.8919 - mse: 246566.0156 - val_loss: 129.9166 - val_mae: 129.9166 - val_mse: 265149.0312\n",
            "Epoch 48/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 119.4961 - mae: 119.4961 - mse: 219206.4844 - val_loss: 133.6462 - val_mae: 133.6462 - val_mse: 269279.5000\n",
            "Epoch 49/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.8487 - mae: 120.8487 - mse: 236421.9375 - val_loss: 142.3693 - val_mae: 142.3693 - val_mse: 279298.5000\n",
            "Epoch 50/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.6410 - mae: 121.6410 - mse: 232836.9844 - val_loss: 129.5010 - val_mae: 129.5010 - val_mse: 264770.8438\n",
            "Epoch 51/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.5847 - mae: 121.5847 - mse: 232862.8438 - val_loss: 133.6680 - val_mae: 133.6680 - val_mse: 269909.2812\n",
            "Epoch 52/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 119.3835 - mae: 119.3835 - mse: 222253.1250 - val_loss: 133.3615 - val_mae: 133.3615 - val_mse: 270857.9375\n",
            "Epoch 53/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.8393 - mae: 120.8393 - mse: 228824.7656 - val_loss: 127.7898 - val_mae: 127.7898 - val_mse: 262363.6562\n",
            "Epoch 54/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.8171 - mae: 120.8171 - mse: 233911.0469 - val_loss: 134.2351 - val_mae: 134.2351 - val_mse: 271834.4062\n",
            "Epoch 55/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.3791 - mae: 122.3791 - mse: 242356.9531 - val_loss: 123.4631 - val_mae: 123.4631 - val_mse: 256050.5156\n",
            "Epoch 56/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 118.6812 - mae: 118.6812 - mse: 216350.4375 - val_loss: 131.9427 - val_mae: 131.9427 - val_mse: 268272.2812\n",
            "Epoch 57/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.3888 - mae: 121.3888 - mse: 235465.6250 - val_loss: 129.1215 - val_mae: 129.1215 - val_mse: 264482.4062\n",
            "Epoch 58/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 119.5655 - mae: 119.5655 - mse: 224449.2969 - val_loss: 134.5904 - val_mae: 134.5904 - val_mse: 269884.9688\n",
            "Epoch 59/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.3223 - mae: 122.3223 - mse: 238275.6094 - val_loss: 137.6109 - val_mae: 137.6109 - val_mse: 272440.9375\n",
            "Epoch 60/100\n",
            "251/251 [==============================] - 1s 4ms/step - loss: 120.4211 - mae: 120.4211 - mse: 230603.1094 - val_loss: 130.6804 - val_mae: 130.6804 - val_mse: 266569.0938\n",
            "Epoch 61/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.7605 - mae: 120.7605 - mse: 226878.3750 - val_loss: 134.2509 - val_mae: 134.2509 - val_mse: 270313.3438\n",
            "Epoch 62/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.7678 - mae: 120.7678 - mse: 233637.2344 - val_loss: 140.1295 - val_mae: 140.1295 - val_mse: 277637.6562\n",
            "Epoch 63/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.7757 - mae: 120.7757 - mse: 230446.0156 - val_loss: 131.2529 - val_mae: 131.2529 - val_mse: 266422.2188\n",
            "Epoch 64/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.5333 - mae: 120.5333 - mse: 225686.6406 - val_loss: 123.4796 - val_mae: 123.4796 - val_mse: 255973.3125\n",
            "Epoch 65/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 119.2767 - mae: 119.2767 - mse: 223934.3438 - val_loss: 129.3575 - val_mae: 129.3575 - val_mse: 265549.5312\n",
            "Epoch 66/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.2216 - mae: 122.2216 - mse: 236488.5781 - val_loss: 132.8578 - val_mae: 132.8578 - val_mse: 270441.7500\n",
            "Epoch 67/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.9243 - mae: 120.9243 - mse: 232637.4844 - val_loss: 130.1568 - val_mae: 130.1568 - val_mse: 266741.7812\n",
            "Epoch 68/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.9540 - mae: 120.9540 - mse: 233046.0625 - val_loss: 133.9737 - val_mae: 133.9737 - val_mse: 270000.0938\n",
            "Epoch 69/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.1139 - mae: 120.1139 - mse: 223343.8750 - val_loss: 138.1440 - val_mae: 138.1440 - val_mse: 276564.7500\n",
            "Epoch 70/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.8031 - mae: 121.8031 - mse: 248968.4844 - val_loss: 139.1503 - val_mae: 139.1503 - val_mse: 274380.0000\n",
            "Epoch 71/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 116.7601 - mae: 116.7601 - mse: 196101.4375 - val_loss: 137.7145 - val_mae: 137.7145 - val_mse: 274304.1250\n",
            "Epoch 72/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.4825 - mae: 122.4825 - mse: 250405.8906 - val_loss: 127.9716 - val_mae: 127.9716 - val_mse: 263305.9375\n",
            "Epoch 73/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.7251 - mae: 121.7251 - mse: 233910.4844 - val_loss: 132.8783 - val_mae: 132.8783 - val_mse: 268876.3438\n",
            "Epoch 74/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 118.3035 - mae: 118.3035 - mse: 217889.7344 - val_loss: 128.0495 - val_mae: 128.0495 - val_mse: 263099.5625\n",
            "Epoch 75/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.7729 - mae: 120.7729 - mse: 228069.7344 - val_loss: 129.6616 - val_mae: 129.6616 - val_mse: 263899.4688\n",
            "Epoch 76/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.3960 - mae: 121.3960 - mse: 236158.7500 - val_loss: 131.3018 - val_mae: 131.3018 - val_mse: 268043.3125\n",
            "Epoch 77/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.9082 - mae: 120.9082 - mse: 237092.7500 - val_loss: 132.5144 - val_mae: 132.5144 - val_mse: 268252.0000\n",
            "Epoch 78/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 118.3045 - mae: 118.3045 - mse: 213108.9531 - val_loss: 138.7087 - val_mae: 138.7087 - val_mse: 276652.8750\n",
            "Epoch 79/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.2491 - mae: 121.2491 - mse: 228366.8438 - val_loss: 128.1301 - val_mae: 128.1301 - val_mse: 262511.2188\n",
            "Epoch 80/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.9592 - mae: 120.9592 - mse: 239876.3906 - val_loss: 132.8331 - val_mae: 132.8331 - val_mse: 268217.5625\n",
            "Epoch 81/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.5693 - mae: 120.5693 - mse: 225783.3906 - val_loss: 136.9185 - val_mae: 136.9185 - val_mse: 272507.8125\n",
            "Epoch 82/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 119.4291 - mae: 119.4291 - mse: 222716.4844 - val_loss: 133.6526 - val_mae: 133.6526 - val_mse: 270063.7500\n",
            "Epoch 83/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.0320 - mae: 120.0320 - mse: 223662.8906 - val_loss: 139.2034 - val_mae: 139.2034 - val_mse: 275201.5312\n",
            "Epoch 84/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.7152 - mae: 120.7152 - mse: 243310.5938 - val_loss: 133.4917 - val_mae: 133.4917 - val_mse: 269770.4062\n",
            "Epoch 85/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.0780 - mae: 121.0780 - mse: 226345.7188 - val_loss: 134.7070 - val_mae: 134.7070 - val_mse: 270042.8750\n",
            "Epoch 86/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 118.0203 - mae: 118.0203 - mse: 217035.0312 - val_loss: 129.9789 - val_mae: 129.9789 - val_mse: 266245.0000\n",
            "Epoch 87/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 122.2074 - mae: 122.2074 - mse: 245223.4531 - val_loss: 132.3447 - val_mae: 132.3447 - val_mse: 267823.7188\n",
            "Epoch 88/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.5337 - mae: 121.5337 - mse: 236850.8438 - val_loss: 133.1748 - val_mae: 133.1748 - val_mse: 270046.9688\n",
            "Epoch 89/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 117.5046 - mae: 117.5046 - mse: 215302.7031 - val_loss: 133.6301 - val_mae: 133.6301 - val_mse: 268976.4375\n",
            "Epoch 90/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.6881 - mae: 121.6881 - mse: 238740.2656 - val_loss: 138.7568 - val_mae: 138.7568 - val_mse: 274009.6562\n",
            "Epoch 91/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 118.7426 - mae: 118.7426 - mse: 220010.0000 - val_loss: 126.7985 - val_mae: 126.7985 - val_mse: 261624.4531\n",
            "Epoch 92/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.9611 - mae: 120.9611 - mse: 238654.7969 - val_loss: 125.7017 - val_mae: 125.7017 - val_mse: 259208.4688\n",
            "Epoch 93/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 120.6259 - mae: 120.6259 - mse: 218023.0938 - val_loss: 128.6374 - val_mae: 128.6374 - val_mse: 263337.3125\n",
            "Epoch 94/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 119.8948 - mae: 119.8948 - mse: 233529.0781 - val_loss: 134.8285 - val_mae: 134.8285 - val_mse: 271494.3125\n",
            "Epoch 95/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 119.1993 - mae: 119.1993 - mse: 222395.5625 - val_loss: 133.3367 - val_mae: 133.3367 - val_mse: 268929.3750\n",
            "Epoch 96/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.0129 - mae: 121.0129 - mse: 236599.4219 - val_loss: 134.6976 - val_mae: 134.6976 - val_mse: 270212.5938\n",
            "Epoch 97/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 118.2708 - mae: 118.2708 - mse: 209827.0938 - val_loss: 136.0791 - val_mae: 136.0791 - val_mse: 273201.8125\n",
            "Epoch 98/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.8548 - mae: 121.8548 - mse: 240987.4062 - val_loss: 125.6924 - val_mae: 125.6924 - val_mse: 260171.4688\n",
            "Epoch 99/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 118.9563 - mae: 118.9563 - mse: 232931.8750 - val_loss: 127.3438 - val_mae: 127.3438 - val_mse: 261761.6719\n",
            "Epoch 100/100\n",
            "251/251 [==============================] - 1s 5ms/step - loss: 121.5988 - mae: 121.5988 - mse: 242316.3281 - val_loss: 129.3836 - val_mae: 129.3836 - val_mse: 265119.2188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.evaluate(enc_X_test, enc_y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctnKxKeajk8U",
        "outputId": "893bae7e-b8ef-4652-a5b2-3d343497ac27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252/252 [==============================] - 1s 2ms/step - loss: 141.9868 - mae: 141.9868 - mse: 350076.5938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[141.98683166503906, 141.98683166503906, 350076.59375]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "new_X_train = X_train[['accommodates', 'bedrooms']]\n",
        "model = LinearRegression()\n",
        "model.fit(new_X_train, y_train)\n",
        "y_pred = model.predict(new_X_train)"
      ],
      "metadata": {
        "id": "iuVhep0tuC_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "mae = mean_absolute_error(y_train, y_pred)\n",
        "mse = mean_squared_error(y_train, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "r2_square = r2_score(y_train, y_pred)\n",
        "print('\\nMAE:', mae)\n",
        "print('\\nMSE:', mse)\n",
        "print('\\nRMSE:', rmse)\n",
        "print('\\nR2 Square', r2_square)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19Q-kafQuR7P",
        "outputId": "767cf93a-8538-40d7-8e9a-b91880d37cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MAE: 155.88386534742628\n",
            "\n",
            "MSE: 245488.75695002434\n",
            "\n",
            "RMSE: 495.4682199193247\n",
            "\n",
            "R2 Square 0.16960915135652954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Keras Example"
      ],
      "metadata": {
        "id": "ALViMgkuY7UP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_dataset(dataframe, target, shuffle=True, batch_size=32):\n",
        "  df = dataframe.copy()\n",
        "  labels = target\n",
        "  df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(batch_size)\n",
        "  return ds"
      ],
      "metadata": {
        "id": "lZcQHAxLJmRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "train_ds = df_to_dataset(X_train, y_train, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU3ixYWCKuAE",
        "outputId": "e9d7d890-ff8c-4060-8134-5016c9105c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(train_features, label_batch)] = train_ds.take(1)\n",
        "print('Every feature:', list(train_features.keys()))\n",
        "print('A batch of description_sentiments:', train_features['description_sentiment'])\n",
        "print('A batch of targets:', label_batch )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7S5_xsxK8Fj",
        "outputId": "1cd5e9a3-e34d-42d8-fed5-be33a0e445a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every feature: ['description_sentiment', 'neighborhood_overview_sentiment', 'host_response_time', 'host_is_superhost', 'host_total_listings_count', 'host_has_profile_pic', 'host_identity_verified', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bedrooms', 'beds', 'essentials', 'luxury', 'appliances', 'entertainment', 'security', 'comfort', 'furniture', 'miscellaneous', 'availability_30', 'number_of_reviews', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'instant_bookable', 'bathroom_qty', 'bathroom_type']\n",
            "A batch of description_sentiments: tf.Tensor(\n",
            "[[b'Neutral']\n",
            " [b'Neutral']\n",
            " [b'Neutral']\n",
            " [b'Neutral']\n",
            " [b'Neutral']], shape=(5, 1), dtype=string)\n",
            "A batch of targets: tf.Tensor([ 50. 259.  68.  35. 201.], shape=(5,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_normalization_layer(name, dataset):\n",
        "  # Create a Normalization layer for the feature.\n",
        "  normalizer = layers.Normalization(axis=None)\n",
        "\n",
        "  # Prepare a Dataset that only yields the feature.\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "  # Learn the statistics of the data.\n",
        "  normalizer.adapt(feature_ds)\n",
        "\n",
        "  return normalizer"
      ],
      "metadata": {
        "id": "ageCqMC9N1xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beds_col = train_features['beds']\n",
        "layer = get_normalization_layer('beds', train_ds)\n",
        "layer(beds_col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFob__I-N3_Y",
        "outputId": "6e7c85d8-2820-4556-ea5b-42745256e467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
              "array([[-0.7189815],\n",
              "       [-0.1618574],\n",
              "       [-0.7189815],\n",
              "       [-0.7189815],\n",
              "       [-0.1618574]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
        "  # Create a layer that turns strings into integer indices.\n",
        "  if dtype == 'string':\n",
        "    index = layers.StringLookup(max_tokens=max_tokens)\n",
        "  # Otherwise, create a layer that turns integer values into integer indices.\n",
        "  else:\n",
        "    index = layers.IntegerLookup(max_tokens=max_tokens)\n",
        "\n",
        "  # Prepare a `tf.data.Dataset` that only yields the feature.\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "  # Learn the set of possible values and assign them a fixed integer index.\n",
        "  index.adapt(feature_ds)\n",
        "\n",
        "  # Encode the integer indices.\n",
        "  encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
        "\n",
        "  # Apply multi-hot encoding to the indices. The lambda function captures the\n",
        "  # layer, so you can use them, or include them in the Keras Functional model later.\n",
        "  return lambda feature: encoder(index(feature))"
      ],
      "metadata": {
        "id": "5xWjax6oOQBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_bathroom_type_col = train_features['bathroom_type']\n",
        "test_type_layer = get_category_encoding_layer(name='bathroom_type',\n",
        "                                              dataset=train_ds,\n",
        "                                              dtype='string')\n",
        "test_type_layer(test_bathroom_type_col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1sl1gBaX3LV",
        "outputId": "880ce2aa-2c14-4219-c9eb-5668c63e9ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 7), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "train_ds = df_to_dataset(X_train, y_train, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(X_test, y_test, shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebj4CDwkwa6D",
        "outputId": "ad363ce4-4cfa-4c16-e25d-e6c6e5dc695f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_inputs = []\n",
        "encoded_features = []\n",
        "\n",
        "# Numerical features.\n",
        "for header in numeric_columns:\n",
        "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
        "  normalization_layer = get_normalization_layer(header, train_ds)\n",
        "  encoded_numeric_col = normalization_layer(numeric_col)\n",
        "  all_inputs.append(numeric_col)\n",
        "  encoded_features.append(encoded_numeric_col)"
      ],
      "metadata": {
        "id": "Hlflq9NZxEbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for header in categorical_columns:\n",
        "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
        "  encoding_layer = get_category_encoding_layer(name=header,\n",
        "                                               dataset=train_ds,\n",
        "                                               dtype='string')\n",
        "  encoded_categorical_col = encoding_layer(categorical_col)\n",
        "  all_inputs.append(categorical_col)\n",
        "  encoded_features.append(encoded_categorical_col)"
      ],
      "metadata": {
        "id": "GW7QBZsFzwwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_features = tf.keras.layers.concatenate(encoded_features)\n",
        "all_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW46LuJi0XH5",
        "outputId": "b6198546-1862-4bdb-f6a2-a15bb9b68627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 462) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.keras.layers.Dense(309, activation=\"relu\")(all_features)\n",
        "x = tf.keras.layers.Dense(309, activation=\"relu\")(x)\n",
        "output = tf.keras.layers.Dense(1)(x)\n",
        "\n",
        "model = tf.keras.Model(all_inputs, output)"
      ],
      "metadata": {
        "id": "NfF-ZvJ31RDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.MeanSquaredError())\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLPpWe1M1U7M",
        "outputId": "9c99c6b4-2883-44d0-922f-76ba1c623d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " description_sentiment (InputLa  [(None, 1)]         0           []                               \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " neighborhood_overview_sentimen  [(None, 1)]         0           []                               \n",
            " t (InputLayer)                                                                                   \n",
            "                                                                                                  \n",
            " host_response_time (InputLayer  [(None, 1)]         0           []                               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " host_is_superhost (InputLayer)  [(None, 1)]         0           []                               \n",
            "                                                                                                  \n",
            " host_has_profile_pic (InputLay  [(None, 1)]         0           []                               \n",
            " er)                                                                                              \n",
            "                                                                                                  \n",
            " host_identity_verified (InputL  [(None, 1)]         0           []                               \n",
            " ayer)                                                                                            \n",
            "                                                                                                  \n",
            " property_type (InputLayer)     [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " room_type (InputLayer)         [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " review_scores_rating (InputLay  [(None, 1)]         0           []                               \n",
            " er)                                                                                              \n",
            "                                                                                                  \n",
            " review_scores_accuracy (InputL  [(None, 1)]         0           []                               \n",
            " ayer)                                                                                            \n",
            "                                                                                                  \n",
            " review_scores_cleanliness (Inp  [(None, 1)]         0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " review_scores_checkin (InputLa  [(None, 1)]         0           []                               \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " review_scores_communication (I  [(None, 1)]         0           []                               \n",
            " nputLayer)                                                                                       \n",
            "                                                                                                  \n",
            " review_scores_location (InputL  [(None, 1)]         0           []                               \n",
            " ayer)                                                                                            \n",
            "                                                                                                  \n",
            " review_scores_value (InputLaye  [(None, 1)]         0           []                               \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " instant_bookable (InputLayer)  [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " bathroom_qty (InputLayer)      [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " bathroom_type (InputLayer)     [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " host_total_listings_count (Inp  [(None, 1)]         0           []                               \n",
            " utLayer)                                                                                         \n",
            "                                                                                                  \n",
            " latitude (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " longitude (InputLayer)         [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " accommodates (InputLayer)      [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " bedrooms (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " beds (InputLayer)              [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " essentials (InputLayer)        [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " luxury (InputLayer)            [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " appliances (InputLayer)        [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " entertainment (InputLayer)     [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " security (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " comfort (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " furniture (InputLayer)         [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " miscellaneous (InputLayer)     [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " availability_30 (InputLayer)   [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " number_of_reviews (InputLayer)  [(None, 1)]         0           []                               \n",
            "                                                                                                  \n",
            " string_lookup_2 (StringLookup)  (None, 1)           0           ['description_sentiment[0][0]']  \n",
            "                                                                                                  \n",
            " string_lookup_3 (StringLookup)  (None, 1)           0           ['neighborhood_overview_sentiment\n",
            "                                                                 [0][0]']                         \n",
            "                                                                                                  \n",
            " string_lookup_4 (StringLookup)  (None, 1)           0           ['host_response_time[0][0]']     \n",
            "                                                                                                  \n",
            " string_lookup_5 (StringLookup)  (None, 1)           0           ['host_is_superhost[0][0]']      \n",
            "                                                                                                  \n",
            " string_lookup_6 (StringLookup)  (None, 1)           0           ['host_has_profile_pic[0][0]']   \n",
            "                                                                                                  \n",
            " string_lookup_7 (StringLookup)  (None, 1)           0           ['host_identity_verified[0][0]'] \n",
            "                                                                                                  \n",
            " string_lookup_8 (StringLookup)  (None, 1)           0           ['property_type[0][0]']          \n",
            "                                                                                                  \n",
            " string_lookup_9 (StringLookup)  (None, 1)           0           ['room_type[0][0]']              \n",
            "                                                                                                  \n",
            " string_lookup_10 (StringLookup  (None, 1)           0           ['review_scores_rating[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " string_lookup_11 (StringLookup  (None, 1)           0           ['review_scores_accuracy[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " string_lookup_12 (StringLookup  (None, 1)           0           ['review_scores_cleanliness[0][0]\n",
            " )                                                               ']                               \n",
            "                                                                                                  \n",
            " string_lookup_13 (StringLookup  (None, 1)           0           ['review_scores_checkin[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " string_lookup_14 (StringLookup  (None, 1)           0           ['review_scores_communication[0][\n",
            " )                                                               0]']                             \n",
            "                                                                                                  \n",
            " string_lookup_15 (StringLookup  (None, 1)           0           ['review_scores_location[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " string_lookup_16 (StringLookup  (None, 1)           0           ['review_scores_value[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " string_lookup_17 (StringLookup  (None, 1)           0           ['instant_bookable[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " string_lookup_18 (StringLookup  (None, 1)           0           ['bathroom_qty[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " string_lookup_19 (StringLookup  (None, 1)           0           ['bathroom_type[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " normalization_3 (Normalization  (None, 1)           3           ['host_total_listings_count[0][0]\n",
            " )                                                               ']                               \n",
            "                                                                                                  \n",
            " normalization_4 (Normalization  (None, 1)           3           ['latitude[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " normalization_5 (Normalization  (None, 1)           3           ['longitude[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " normalization_6 (Normalization  (None, 1)           3           ['accommodates[0][0]']           \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " normalization_7 (Normalization  (None, 1)           3           ['bedrooms[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " normalization_8 (Normalization  (None, 1)           3           ['beds[0][0]']                   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " normalization_9 (Normalization  (None, 1)           3           ['essentials[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " normalization_10 (Normalizatio  (None, 1)           3           ['luxury[0][0]']                 \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " normalization_11 (Normalizatio  (None, 1)           3           ['appliances[0][0]']             \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " normalization_12 (Normalizatio  (None, 1)           3           ['entertainment[0][0]']          \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " normalization_13 (Normalizatio  (None, 1)           3           ['security[0][0]']               \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " normalization_14 (Normalizatio  (None, 1)           3           ['comfort[0][0]']                \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " normalization_15 (Normalizatio  (None, 1)           3           ['furniture[0][0]']              \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " normalization_16 (Normalizatio  (None, 1)           3           ['miscellaneous[0][0]']          \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " normalization_17 (Normalizatio  (None, 1)           3           ['availability_30[0][0]']        \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " normalization_18 (Normalizatio  (None, 1)           3           ['number_of_reviews[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " category_encoding_2 (CategoryE  (None, 9)           0           ['string_lookup_2[0][0]']        \n",
            " ncoding)                                                                                         \n",
            "                                                                                                  \n",
            " category_encoding_3 (CategoryE  (None, 9)           0           ['string_lookup_3[0][0]']        \n",
            " ncoding)                                                                                         \n",
            "                                                                                                  \n",
            " category_encoding_4 (CategoryE  (None, 6)           0           ['string_lookup_4[0][0]']        \n",
            " ncoding)                                                                                         \n",
            "                                                                                                  \n",
            " category_encoding_5 (CategoryE  (None, 3)           0           ['string_lookup_5[0][0]']        \n",
            " ncoding)                                                                                         \n",
            "                                                                                                  \n",
            " category_encoding_6 (CategoryE  (None, 3)           0           ['string_lookup_6[0][0]']        \n",
            " ncoding)                                                                                         \n",
            "                                                                                                  \n",
            " category_encoding_7 (CategoryE  (None, 3)           0           ['string_lookup_7[0][0]']        \n",
            " ncoding)                                                                                         \n",
            "                                                                                                  \n",
            " category_encoding_8 (CategoryE  (None, 118)         0           ['string_lookup_8[0][0]']        \n",
            " ncoding)                                                                                         \n",
            "                                                                                                  \n",
            " category_encoding_9 (CategoryE  (None, 5)           0           ['string_lookup_9[0][0]']        \n",
            " ncoding)                                                                                         \n",
            "                                                                                                  \n",
            " category_encoding_10 (Category  (None, 35)          0           ['string_lookup_10[0][0]']       \n",
            " Encoding)                                                                                        \n",
            "                                                                                                  \n",
            " category_encoding_11 (Category  (None, 36)          0           ['string_lookup_11[0][0]']       \n",
            " Encoding)                                                                                        \n",
            "                                                                                                  \n",
            " category_encoding_12 (Category  (None, 39)          0           ['string_lookup_12[0][0]']       \n",
            " Encoding)                                                                                        \n",
            "                                                                                                  \n",
            " category_encoding_13 (Category  (None, 33)          0           ['string_lookup_13[0][0]']       \n",
            " Encoding)                                                                                        \n",
            "                                                                                                  \n",
            " category_encoding_14 (Category  (None, 32)          0           ['string_lookup_14[0][0]']       \n",
            " Encoding)                                                                                        \n",
            "                                                                                                  \n",
            " category_encoding_15 (Category  (None, 32)          0           ['string_lookup_15[0][0]']       \n",
            " Encoding)                                                                                        \n",
            "                                                                                                  \n",
            " category_encoding_16 (Category  (None, 35)          0           ['string_lookup_16[0][0]']       \n",
            " Encoding)                                                                                        \n",
            "                                                                                                  \n",
            " category_encoding_17 (Category  (None, 3)           0           ['string_lookup_17[0][0]']       \n",
            " Encoding)                                                                                        \n",
            "                                                                                                  \n",
            " category_encoding_18 (Category  (None, 38)          0           ['string_lookup_18[0][0]']       \n",
            " Encoding)                                                                                        \n",
            "                                                                                                  \n",
            " category_encoding_19 (Category  (None, 7)           0           ['string_lookup_19[0][0]']       \n",
            " Encoding)                                                                                        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 462)          0           ['normalization_3[0][0]',        \n",
            "                                                                  'normalization_4[0][0]',        \n",
            "                                                                  'normalization_5[0][0]',        \n",
            "                                                                  'normalization_6[0][0]',        \n",
            "                                                                  'normalization_7[0][0]',        \n",
            "                                                                  'normalization_8[0][0]',        \n",
            "                                                                  'normalization_9[0][0]',        \n",
            "                                                                  'normalization_10[0][0]',       \n",
            "                                                                  'normalization_11[0][0]',       \n",
            "                                                                  'normalization_12[0][0]',       \n",
            "                                                                  'normalization_13[0][0]',       \n",
            "                                                                  'normalization_14[0][0]',       \n",
            "                                                                  'normalization_15[0][0]',       \n",
            "                                                                  'normalization_16[0][0]',       \n",
            "                                                                  'normalization_17[0][0]',       \n",
            "                                                                  'normalization_18[0][0]',       \n",
            "                                                                  'category_encoding_2[0][0]',    \n",
            "                                                                  'category_encoding_3[0][0]',    \n",
            "                                                                  'category_encoding_4[0][0]',    \n",
            "                                                                  'category_encoding_5[0][0]',    \n",
            "                                                                  'category_encoding_6[0][0]',    \n",
            "                                                                  'category_encoding_7[0][0]',    \n",
            "                                                                  'category_encoding_8[0][0]',    \n",
            "                                                                  'category_encoding_9[0][0]',    \n",
            "                                                                  'category_encoding_10[0][0]',   \n",
            "                                                                  'category_encoding_11[0][0]',   \n",
            "                                                                  'category_encoding_12[0][0]',   \n",
            "                                                                  'category_encoding_13[0][0]',   \n",
            "                                                                  'category_encoding_14[0][0]',   \n",
            "                                                                  'category_encoding_15[0][0]',   \n",
            "                                                                  'category_encoding_16[0][0]',   \n",
            "                                                                  'category_encoding_17[0][0]',   \n",
            "                                                                  'category_encoding_18[0][0]',   \n",
            "                                                                  'category_encoding_19[0][0]']   \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 309)          143067      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 309)          95790       ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            310         ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 239,215\n",
            "Trainable params: 239,167\n",
            "Non-trainable params: 48\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZA6I17R4dHG",
        "outputId": "09032d57-619e-412f-b991-e00e3e1f10d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "252/252 [==============================] - 8s 21ms/step - loss: 257114.7031\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 6s 20ms/step - loss: 217166.3281\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 6s 20ms/step - loss: 201859.2812\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 7s 24ms/step - loss: 185668.0156\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 163884.5156\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 6s 20ms/step - loss: 143398.7656\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 8s 24ms/step - loss: 132281.0781\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 125137.7422\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 7s 22ms/step - loss: 120586.1641\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 116724.2734\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 113686.4609\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 110785.5859\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 8s 27ms/step - loss: 107094.2344\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 10s 36ms/step - loss: 105631.0703\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 11s 37ms/step - loss: 102929.5781\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 13s 44ms/step - loss: 100799.0938\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 12s 41ms/step - loss: 98776.0312\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 11s 37ms/step - loss: 96563.4844\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 94593.3516\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 92225.6406\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 91016.0938\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 89078.3125\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 7s 24ms/step - loss: 87280.5781\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 85779.5078\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 83867.7891\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 82652.2734\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 7s 22ms/step - loss: 80887.3047\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 79632.9766\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 77775.9688\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 7s 22ms/step - loss: 76940.8516\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 8s 27ms/step - loss: 75508.2344\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 7s 24ms/step - loss: 74033.0547\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 7s 24ms/step - loss: 72589.2578\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 71511.1484\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 70139.4375\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 68999.9141\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 7s 24ms/step - loss: 67956.4688\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 67397.6016\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 65636.4531\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 64973.2812\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 63034.5000\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 62140.9883\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 61654.7539\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 60841.5742\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 59762.3906\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 58328.6328\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 57889.5000\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 7s 22ms/step - loss: 56914.4922\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 6s 20ms/step - loss: 55956.3750\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 54952.1328\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 54696.5039\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 54282.7734\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 7s 22ms/step - loss: 53175.0039\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 52760.8711\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 51501.4570\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 51406.7227\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 8s 27ms/step - loss: 50322.8750\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 8s 26ms/step - loss: 49762.6250\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 8s 27ms/step - loss: 48994.9453\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 48453.9922\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 47273.7969\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 46853.2812\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 46582.9727\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 7s 22ms/step - loss: 45887.0195\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 7s 22ms/step - loss: 45200.7031\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 44936.8555\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 44527.5820\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 7s 22ms/step - loss: 43804.9688\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 43189.3203\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 42935.0898\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 7s 23ms/step - loss: 42561.0938\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 6s 22ms/step - loss: 41470.8203\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 41410.1367\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 40837.6797\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 40310.7773\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 40342.7852\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 39401.6914\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 39349.9062\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 38738.9648\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 38634.0078\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 37832.1367\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 37495.2148\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 6s 20ms/step - loss: 37672.3398\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 37423.1875\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 37017.3516\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 36595.3828\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 35672.0078\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 35274.1797\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 6s 20ms/step - loss: 35134.0078\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 35065.5156\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 34494.2578\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 6s 20ms/step - loss: 33882.9727\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 6s 20ms/step - loss: 34307.6953\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 33555.8828\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 32826.5312\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 6s 21ms/step - loss: 33389.1562\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 6s 20ms/step - loss: 33068.5117\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 6s 19ms/step - loss: 32197.1895\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 5s 18ms/step - loss: 33099.4062\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 5s 18ms/step - loss: 32311.8379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNZNCwB-J7tp",
        "outputId": "f8f18963-75ca-4d28-b622-c46e77321e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcknAnNOMlUo",
        "outputId": "71864d07-cbac-4228-b07c-55e82b8173b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 11ms/step - loss: 161709.1250\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "161709.125"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXZWrkajMtMx",
        "outputId": "363f1a0c-b5e3-46ce-83fd-ccc1ab41c6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         334.0\n",
              "1         105.0\n",
              "2         329.0\n",
              "3         151.0\n",
              "4         180.0\n",
              "          ...  \n",
              "16117     116.0\n",
              "16118     456.0\n",
              "16119    5999.0\n",
              "16120      99.0\n",
              "16121     100.0\n",
              "Name: price, Length: 16122, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ]
}